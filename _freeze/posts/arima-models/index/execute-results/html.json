{
  "hash": "a4031e1fd1b81086b6bfb1918f5bc487",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Basic Concepts in Forecasting\"\nbibliography: \"../../blog.bib\"\nauthor: \"Peter Amerkhanian\"\ndate: \"2024-3-17\"\ncategories: ['R', 'Statistics']\nformat:\n  html:\n    warning: false\n    df-print: kable\n    fig-dpi: 300\n    toc: true\n    toc-depth: 3\n    code-fold: false\n    code-tools: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(arrow)\nlibrary(fpp3)\nlibrary(knitr)\nlibrary(ggdist)\n```\n:::\n\n\nLet's say we are analyzing the data in the BART time series that I've been using a various blog posts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparquet_directory <- \"../dask-data-io/data/parquet_data\"\n\ndf <- open_dataset(parquet_directory)\n\ndf_daily <- df %>%\n  group_by(Date) %>%\n  summarise(daily_riders=sum(Riders)) %>%\n  mutate(date=as.Date(Date)) %>%\n  select(c(date, daily_riders)) %>% \n  collect()\n\ndf_daily %>% head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|date       | daily_riders|\n|:----------|------------:|\n|2011-01-01 |       124971|\n|2011-01-02 |        94276|\n|2011-01-03 |       286747|\n|2011-01-04 |       323233|\n|2011-01-05 |       327972|\n|2011-01-06 |       330048|\n\n</div>\n:::\n:::\n\nI'll create a `tstibble` of monthly BART riders, 2011 through the end of 2018 and run through some exercises where I try to forecast how many monthly riders there will be in 2019.  \n\nHere's the groundtruth dataset for $[2011, 2019]$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_daily_ts <- df_daily %>% \n  as_tsibble(index=date) %>%\n  filter_index(\"2011-01-01\" ~ \"2018-12-31\")\n\ndf_monthly_ts <- df_daily_ts %>%\n  group_by_key() %>%\n  index_by(year_month = ~ yearmonth(.)) %>% \n  summarise(\n    monthly_riders = sum(daily_riders, na.rm = TRUE),\n  )\n\ndf_monthly_ts %>% head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|year_month | monthly_riders|\n|:----------|--------------:|\n|2011 Jan   |        8203562|\n|2011 Feb   |        7933264|\n|2011 Mar   |        9049039|\n|2011 Apr   |        8824840|\n|2011 May   |        8940380|\n|2011 Jun   |        9210691|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Create the date dynamically\nearliest_date <- min(df_monthly_ts$year_month)\nlatest_date <- max(df_monthly_ts$year_month)\nformatted_string <- sprintf(\"%s through %s\",\n                            format(earliest_date, \"%b %Y\"),\n                            format(latest_date, \"%b %Y\"))\ncolor <- \"\"\n\nplot_bart_series <- function(title, subtitle) {\n  df_monthly_ts %>%\n    ggplot(aes(x = year_month, y = monthly_riders)) +\n    geom_line(linewidth = .9,\n              alpha = 1,\n              color = \"#619CFF\")   +\n    scale_y_continuous(labels = scales::comma_format()) +\n    theme_minimal() +\n    labs(\n      title = title,\n      subtitle = if (missing(subtitle)) {\n        \"\"\n      } else {\n        subtitle\n      },\n      y = \"Riders\",\n      x = \"Month\"\n    )\n}\nplot_bart_series(\"Monthly Bart Rides\", formatted_string)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=2100}\n:::\n:::\n\n\n\nWhen analyzing a time series, we often want to produce a forecast, $\\hat{y}_{T+h|T}$. I found this to be a weird looking term when I first saw it in [@hyndman_forecasting_2021], so I'll break down what it's referring to here:  \n\n1.  $\\hat{y}$: The \"hat\" symbol (^) over the ($y$) indicates that\n    this is an estimated value.\n2.  $T$: This represents the most recent observation from the time series.\n3.  $h$: This is the \"forecast horizon\", indicating how many time\n    steps ahead from (T) we are forecasting.\n4.  $|T$: The vertical bar ($|$) followed by ($T$) signifies that\n    the forecast is conditional on the information available up to time\n    (T).  \n\nThus,$\\hat{y}_{T+h|T}$ is a forecast of the time series, $y$ at time $T+h$, given the\ninformation available up to and including time $T$.\n\n## Benchmark Forecasts\n\n\n### Predicting the mean\nOne of the most straightforward prediction models in the mean, a single scalar that minimizes mean-squared error across the data.\n\n$$\n\\hat{y}_{T+h|T} = \\frac{1}{T} \\sum_{i=1}^T y_{i}\n$$\nWe can calculate that on our BART data:\n\n::: {.cell}\n\n```{.r .cell-code}\npred <- mean(df_monthly_ts$monthly_riders)\npred\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10023511\n```\n\n\n:::\n:::\n\nSo if we are forecasting with the mean, we'll simply predict always predict $\\hat{y}=$10\\,023\\,511 as the monthly rider total for all months going forward.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_mean <- df_monthly_ts %>%\n  model(Mean = MEAN(monthly_riders))\nplot_bart_series(\"Mean Forecast\") +\n  geom_line(\n    data = fc_mean %>% forecast(h = 12),\n    linewidth = 1,\n    linetype=\"dotted\",\n    aes(x = year_month, y = .mean, color = \"Forecast\")\n  ) +\n  geom_line(\n    data = fc_mean %>% augment(),\n    linewidth = 1,\n    alpha=.5,\n    aes(x = year_month, y = .fitted, color = \"Fitted\")\n  ) +\n  labs(color = \"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=2100}\n:::\n:::\n\n\n#### Model Evaluation\n\nIf we want to evaluate that prediction, we would look at its residuals, $\\hat{y}-y$, across the observed data. Here we'll take a look at the distribution of these residuals, which will be important for both model evaluation and model inference.\n\n::: {.cell}\n\n```{.r .cell-code}\nresiduals <- df_monthly_ts$monthly_riders - pred\nresiduals %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2090248  -617574    19581        0   711366  1742004 \n```\n\n\n:::\n:::\n\nThe most important checks on these are that their mean is 0 and that the residuals are not auto-correlated -- if those two conditions don't hold, that means that **the model can be improved**. In addition to those essential properties, it is also preferable that the residuals exhibit constant variance (homoscedasticity) and are normally distributed, but a model that fails on those last two conditions cannot necessarily be improved  [@hyndman_forecasting_2021, chap 5.4].  \n\nWe can use `gg_tsresiduals()` from the `feast` package to get some simple visuals that let us evaluate these diagnostics:\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_monthly_ts |>\n  model(MEAN(monthly_riders)) |>\n  gg_tsresiduals()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=2100}\n:::\n:::\n\nFrom these visuals, I'll informally conclude that:  \n \n1. The mean is 0\n2. There is significant autocorrelation \n3. The residuals *look* kind of normally distributed\n4. The variance of the residuals is not constant -- we start out systematically overestimating ridership\n\nGiven that we failed on autocorrelation, we conclude that this model can be improved, and this is unsurprising given that we were just predicting the mean. However, we'll keep working with this model as we establish how to do inference on this forecast and produce prediction intervals, rather than just a point estimate forecast.\n\n#### Model Inference\n\nIf we **assume that the distribution of future observations is normal**, a 95% prediction interval would be computed as follows:  \n$$\n\\hat{y}_{T+h|T} \\pm 1.96 \\hat\\sigma_h\n$$\nThis follows from the fact that 95% of the area under a Gaussian curve lies within ~1.96 standard deviations, or, $1.96 \\hat\\sigma_h$, of the mean ([see proof](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule#Proof)). 1.96 can be switched out with a different multiplier depending on the desired interval ([see table](https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-1)). When we are forecasting, the standard deviation of the forecast distribution is estimated using the [corrected sample standard deviation](https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation) of the residuals.\n$$\n\\begin{equation}\n  \\hat{\\sigma} = \\sqrt{\\frac{1}{T-K-M}\\sum_{t=1}^T e_t^2}\n\\end{equation}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nT <- df_monthly_ts %>% dim() %>% .[1]\nK <- 1\nM <- 0\nsample_sd <- sqrt( (1 / (T - K - M)) * sum(residuals^2) )\ninterval_95 <- 1.96 * sample_sd\ninterval_95\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1575196\n```\n\n\n:::\n:::\n\nSo for our mean forecast, the prediction interval would be 10\\,023\\,511 $\\pm$ 1\\,575\\,196 \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_mean <- df_monthly_ts %>%\n  model(MEAN(monthly_riders)) %>%\n  forecast(h=12)\nplot_bart_series(\"Mean Forecast\") + autolayer(fc_mean)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=2100}\n:::\n:::\n\n\nWe can also relax some of the assumptions necessary for theoretical inference by using bootstrapping, where we only have to assume that the residuals are uncorrelated and have constant variance. To be fair, both of these conditions are violated in this example model, but we'll still bootstrap this as an example.  \n\nWhen we bootstrap a time series forecast, we use the following equation:  \n\n$$\n\\begin{align*}\ny^*_{T+1} &= y_{T} + e^*_{T+1} \\\\\ny^*_{T+2} &= y_{T+1}^* + e^*_{T+2} \\\\\n\\vdots \\\\\ny^*_{T+h} &= y_{T+h-1}^* + e^*_{T+h} \\\\\n\n\\end{align*}\n$$   \n\nWhere each $e^*_{T+h}$ is a random sample with replacement from the residuals distribution.  \n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nbootstrapped_fs <- df_monthly_ts %>%\n  model(MEAN(monthly_riders)) %>%\n  generate(h = 12, times = 1, bootstrap = TRUE)\n\nplot_bart_series(\"\") +\n  geom_line(data = bootstrapped_fs, alpha=.5, linewidth=1, aes(y = .sim, colour = as.factor(.rep) )) +\n  guides(colour = \"none\")\n```\n\n::: {.cell-output-display}\n![Bootstrap Simulations, b=1](index_files/figure-html/unnamed-chunk-11-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nfc_mean <- df_monthly_ts %>%\n  model(MEAN(monthly_riders)) %>%\n  forecast(h=12, bootstrap = TRUE, times = 5000)\nplot_bart_series(\"\") + autolayer(fc_mean) +\n  theme(axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank())\n```\n\n::: {.cell-output-display}\n![Bootstrapped Prediction Interval, b=5000](index_files/figure-html/unnamed-chunk-11-2.png){width=2100}\n:::\n:::\n\n\n\n\n\n### Random Walk\n\n$$\n\\hat{y}_{T+h|T} = y_T\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_mean <- df_monthly_ts %>%\n  model(Naive = NAIVE(monthly_riders))\nplot_bart_series(\"Mean Forecast\") +\n  geom_line(\n    data = fc_mean %>% forecast(h = 12),\n    linewidth = 1,\n    linetype=\"solid\",\n    aes(x = year_month, y = .mean, color = \"Forecast\")\n  ) +\n  geom_line(\n    data = fc_mean %>% augment(),\n    linewidth = 1,\n    linetype = \"solid\",\n    alpha=.5,\n    aes(x = year_month, y = .fitted, color = \"Fitted\")\n  ) +\n  labs(color = \"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=2100}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfc_mean <- df_monthly_ts %>%\n  model(snaive = SNAIVE(monthly_riders))\nplot_bart_series(\"Mean Forecast\") +\n  geom_line(\n    data = fc_mean %>% forecast(h = 12),\n    linewidth = 1,\n    linetype=\"solid\",\n    aes(x = year_month, y = .mean, color = \"Forecast\")\n  ) +\n  geom_line(\n    data = fc_mean %>% augment(),\n    linewidth = 1,\n    linetype = \"solid\",\n    alpha=.5,\n    aes(x = year_month, y = .fitted, color = \"Fitted\")\n  ) +\n  labs(color = \"\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=2100}\n:::\n:::\n\n\n## Exponential Smoothing\n\nExponential Smoothing is a popular forecasting method where the forecast\nis simply a weighted average of past observations, with weights\ndecreasing exponentially as observations get older\n[@hyndman_forecasting_2021, chapter 8].\n\n[@hyndman_forecasting_2021, chapter 9]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fpp3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nalgeria_economy <- global_economy |>\n  filter(Country == \"Algeria\")\nalgeria_economy \n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Country |Code | Year|          GDP|      Growth|        CPI|  Imports|  Exports| Population|\n|:-------|:----|----:|------------:|-----------:|----------:|--------:|--------:|----------:|\n|Algeria |DZA  | 1960|   2723648552|          NA|         NA| 67.14363| 39.04317|   11124888|\n|Algeria |DZA  | 1961|   2434776646| -13.6054413|         NA| 67.50377| 46.24456|   11404859|\n|Algeria |DZA  | 1962|   2001468868| -19.6850418|         NA| 20.81865| 19.79387|   11690153|\n|Algeria |DZA  | 1963|   2703014867|  34.3137288|         NA| 36.82552| 24.68468|   11985136|\n|Algeria |DZA  | 1964|   2909351793|   5.8394130|         NA| 29.43976| 25.08406|   12295970|\n|Algeria |DZA  | 1965|   3136258897|   6.2068982|         NA| 25.83308| 22.60394|   12626952|\n|Algeria |DZA  | 1966|   3039834559|  -4.8049709|         NA| 24.65357| 25.98620|   12980267|\n|Algeria |DZA  | 1967|   3370843066|   9.4529626|         NA| 21.63177| 23.43442|   13354197|\n|Algeria |DZA  | 1968|   3852115817|  10.7962386|         NA| 24.18725| 23.13563|   13744387|\n|Algeria |DZA  | 1969|   4257218772|   8.4332803|   2.569024| 28.07076| 23.78878|   14144438|\n|Algeria |DZA  | 1970|   4863487493|   8.8626571|   2.738580| 29.15267| 22.07273|   14550034|\n|Algeria |DZA  | 1971|   5077222367| -11.3317192|   2.810513| 27.66378| 18.44252|   14960109|\n|Algeria |DZA  | 1972|   6761786387|  27.4239695|   2.913274| 25.72687| 20.44956|   15377093|\n|Algeria |DZA  | 1973|   8715105930|   3.8131763|   3.093106| 31.58976| 25.50366|   15804428|\n|Algeria |DZA  | 1974|  13209713643|   7.4949177|   3.238469| 35.48978| 38.74904|   16247113|\n|Algeria |DZA  | 1975|  15557934268|   5.0453416|   3.505006| 42.96560| 33.68894|   16709099|\n|Algeria |DZA  | 1976|  17728347375|   8.3867565|   3.835554| 37.11867| 33.05458|   17190239|\n|Algeria |DZA  | 1977|  20971901273|   5.2585860|   4.295409| 41.74032| 30.58657|   17690184|\n|Algeria |DZA  | 1978|  26364491313|   9.2148357|   5.048133| 40.16873| 25.53584|   18212326|\n|Algeria |DZA  | 1979|  33243422158|   7.4778266|   5.621026| 32.86575| 31.14830|   18760761|\n|Algeria |DZA  | 1980|  42345277342|   0.7906070|   6.156025| 30.33846| 34.33846|   19337715|\n|Algeria |DZA  | 1981|  44348672668|   2.9999961|   7.058181| 30.87774| 34.58725|   19943664|\n|Algeria |DZA  | 1982|  45207088716|   6.4000041|   7.519963| 28.99807| 30.92486|   20575701|\n|Algeria |DZA  | 1983|  48801369800|   5.4000030|   7.968692| 25.80231| 27.94181|   21228289|\n|Algeria |DZA  | 1984|  53698278906|   5.5999965|   8.615462| 27.46637| 25.71002|   21893853|\n|Algeria |DZA  | 1985|  57937868670|   3.6999973|   9.518560| 26.74219| 23.58393|   22565905|\n|Algeria |DZA  | 1986|  63696301893|   0.4000010|  10.696159| 23.17195| 12.85476|   23241272|\n|Algeria |DZA  | 1987|  66742267773|  -0.6999975|  11.492088| 18.41211| 14.27247|   23917897|\n|Algeria |DZA  | 1988|  59089067187|  -1.0000055|  12.171448| 22.60372| 15.50787|   24591492|\n|Algeria |DZA  | 1989|  55631489802|   4.4000022|  13.303923| 28.51406| 18.63926|   25257672|\n|Algeria |DZA  | 1990|  62045099643|   0.8000006|  15.519364| 24.93703| 23.44369|   25912367|\n|Algeria |DZA  | 1991|  45715367087|  -1.2000006|  19.536766| 23.59976| 29.11782|   26554329|\n|Algeria |DZA  | 1992|  48003298223|   1.8000023|  25.723994| 23.86949| 25.31959|   27181094|\n|Algeria |DZA  | 1993|  49946455211|  -2.1000008|  31.007786| 23.13894| 21.78388|   27786259|\n|Algeria |DZA  | 1994|  42542571306|  -0.8999965|  40.014821| 26.05371| 22.53073|   28362253|\n|Algeria |DZA  | 1995|  41764052458|   3.7999948|  51.931085| 28.99623| 26.19478|   28904298|\n|Algeria |DZA  | 1996|  46941496780|   4.0999985|  61.631332| 23.94470| 29.76045|   29411415|\n|Algeria |DZA  | 1997|  48177862502|   1.0999999|  65.164979| 21.33760| 30.90631|   29886839|\n|Algeria |DZA  | 1998|  48187747529|   5.1000036|  68.390750| 22.51610| 22.57835|   30335732|\n|Algeria |DZA  | 1999|  48640574567|   3.2000016|  70.200035| 22.77900| 28.15012|   30765613|\n|Algeria |DZA  | 2000|  54790245601|   3.8196785|  70.438128| 20.78863| 42.06972|   31183660|\n|Algeria |DZA  | 2001|  54744714396|   3.0083955|  73.414835| 22.01686| 36.68930|   31592153|\n|Algeria |DZA  | 2002|  56760288974|   5.6093232|  74.456079| 25.62963| 35.50453|   31995046|\n|Algeria |DZA  | 2003|  67863829880|   7.2018722|  77.634575| 23.87594| 38.24883|   32403514|\n|Algeria |DZA  | 2004|  85324998814|   4.3016243|  80.710302| 25.64820| 40.05323|   32831096|\n|Algeria |DZA  | 2005| 103198228459|   5.9077913|  81.826078| 24.07340| 47.20519|   33288437|\n|Algeria |DZA  | 2006| 117027304747|   1.6844883|  83.717488| 21.91933| 48.81069|   33777915|\n|Algeria |DZA  | 2007| 134977087734|   3.3728752|  86.797450| 24.86996| 47.06816|   34300076|\n|Algeria |DZA  | 2008| 171000691878|   2.3601349|  91.014583| 28.71118| 47.97335|   34860715|\n|Algeria |DZA  | 2009| 137211039898|   1.6322438|  96.236145| 35.95268| 35.37165|   35465760|\n|Algeria |DZA  | 2010| 161207268655|   3.6341454| 100.000000| 31.42211| 38.44455|   36117637|\n|Algeria |DZA  | 2011| 200019057308|   2.8918660| 104.524212| 28.68532| 38.78695|   36819558|\n|Algeria |DZA  | 2012| 209058991952|   3.3747687| 113.817931| 28.51443| 36.89055|   37565847|\n|Algeria |DZA  | 2013| 209755003251|   2.7676389| 117.521838| 30.40093| 33.20990|   38338562|\n|Algeria |DZA  | 2014| 213810022462|   3.7891212| 120.949864| 31.92666| 30.21912|   39113313|\n|Algeria |DZA  | 2015| 165979277277|   3.7634670| 126.736646| 36.52335| 23.17178|   39871528|\n|Algeria |DZA  | 2016| 160129866570|   3.3000000| 134.844870| 35.03223| 20.86001|   40606052|\n|Algeria |DZA  | 2017| 167555280113|   1.6000000| 142.384203| 33.50147| 22.63889|   41318142|\n\n</div>\n:::\n\n```{.r .cell-code}\noptim\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfunction (par, fn, gr = NULL, ..., method = c(\"Nelder-Mead\", \n    \"BFGS\", \"CG\", \"L-BFGS-B\", \"SANN\", \"Brent\"), lower = -Inf, \n    upper = Inf, control = list(), hessian = FALSE) \n{\n    fn1 <- function(par) fn(par, ...)\n    gr1 <- if (!is.null(gr)) \n        function(par) gr(par, ...)\n    method <- match.arg(method)\n    if ((any(lower > -Inf) || any(upper < Inf)) && !any(method == \n        c(\"L-BFGS-B\", \"Brent\"))) {\n        warning(\"bounds can only be used with method L-BFGS-B (or Brent)\")\n        method <- \"L-BFGS-B\"\n    }\n    npar <- length(par)\n    con <- list(trace = 0, fnscale = 1, parscale = rep.int(1, \n        npar), ndeps = rep.int(0.001, npar), maxit = 100L, abstol = -Inf, \n        reltol = sqrt(.Machine$double.eps), alpha = 1, beta = 0.5, \n        gamma = 2, REPORT = 10, warn.1d.NelderMead = TRUE, type = 1, \n        lmm = 5, factr = 1e+07, pgtol = 0, tmax = 10, temp = 10)\n    nmsC <- names(con)\n    if (method == \"Nelder-Mead\") \n        con$maxit <- 500\n    if (method == \"SANN\") {\n        con$maxit <- 10000\n        con$REPORT <- 100\n    }\n    con[(namc <- names(control))] <- control\n    if (length(noNms <- namc[!namc %in% nmsC])) \n        warning(\"unknown names in control: \", paste(noNms, collapse = \", \"))\n    if (con$trace < 0) \n        warning(\"read the documentation for 'trace' more carefully\")\n    else if (method == \"SANN\" && con$trace && as.integer(con$REPORT) == \n        0) \n        stop(\"'trace != 0' needs 'REPORT >= 1'\")\n    if (method == \"L-BFGS-B\" && any(!is.na(match(c(\"reltol\", \n        \"abstol\"), namc)))) \n        warning(\"method L-BFGS-B uses 'factr' (and 'pgtol') instead of 'reltol' and 'abstol'\")\n    if (npar == 1 && method == \"Nelder-Mead\" && isTRUE(con$warn.1d.NelderMead)) \n        warning(\"one-dimensional optimization by Nelder-Mead is unreliable:\\nuse \\\"Brent\\\" or optimize() directly\")\n    if (npar > 1 && method == \"Brent\") \n        stop(\"method = \\\"Brent\\\" is only available for one-dimensional optimization\")\n    lower <- as.double(rep_len(lower, npar))\n    upper <- as.double(rep_len(upper, npar))\n    res <- if (method == \"Brent\") {\n        if (any(!is.finite(c(upper, lower)))) \n            stop(\"'lower' and 'upper' must be finite values\")\n        res <- optimize(function(par) fn(par, ...)/con$fnscale, \n            lower = lower, upper = upper, tol = con$reltol)\n        names(res)[names(res) == c(\"minimum\", \"objective\")] <- c(\"par\", \n            \"value\")\n        res$value <- res$value * con$fnscale\n        c(res, list(counts = c(`function` = NA, gradient = NA), \n            convergence = 0L, message = NULL))\n    }\n    else .External2(C_optim, par, fn1, gr1, method, con, lower, \n        upper)\n    if (hessian) \n        res$hessian <- .External2(C_optimhess, res$par, fn1, \n            gr1, con)\n    res\n}\n<bytecode: 0x0000025146aad168>\n<environment: namespace:stats>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2015 <- gafa_stock %>% \n  filter(Symbol == \"GOOG\", year(Date) == 2018)\n\ngoogle_2015 %>% autoplot(Close)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=2100}\n:::\n\n```{.r .cell-code}\ngoogle_2015 %>% ACF(Close) %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-2.png){width=2100}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2015 %>% autoplot(difference(Close))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=2100}\n:::\n\n```{.r .cell-code}\ngoogle_2015 %>% ACF(difference(Close)) %>% autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-2.png){width=2100}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}