{
  "hash": "48277a291f1bc25736f42f2ab9192164",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Working with ACS microdata in R\"\nbibliography: \"../../blog.bib\"\nauthor: \"Peter Amerkhanian\"\ndate: \"2024-12-29\"\ndescription: \"A general overview of retrieving and working with IPUMS data in R using `ipumsr` and `survey`.\"\ndraft: true\nimage: thumbnail.png\nengine: knitr\nexecute: \n  cache: false\n  freeze: auto\ncategories: ['R', 'Data Management']\nformat:\n  html:\n    df-print: kable\n    toc: true\n    toc-depth: 3\n    code-fold: false\n    code-tools: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npacman::p_load(dplyr,\n               ggplot2,\n               # Statistics\n               modelsummary,\n               srvyr,\n               survey,\n               # Webscraping\n               httr,\n               rvest,\n               readr,\n               glue,\n               # Census\n               tidycensus,\n               ipumsr)\n\ngof_stuff <- tribble(\n  ~ raw, ~ clean, ~ fmt,\n  \"nobs\", \"N\", 0,\n  \"r.squared\", \"R²\", 3\n  )\n```\n:::\n\n\n\n\nIn this post, I'm going to cover how to use American Community Survey\n(ACS) microdata, leveraging the University of Minnesota's Integrated\nPublic Use Microdata Series (IPUMS).[^1] I'll cover:\n\n[^1]: I want to note that several of the points I cover here are things\n    I learned from some coworkers-- [Bert\n    Wilden](https://www.bwilden.com/) and Stephanie Peng.\n\n1.  **Retrieval**: how to choose which ACS product is relevant, how to\n    submit a request to IPUMS, and how to filter down to relevant levels\n    of geography/granularity.\n2.  **Analysis**: how to properly weight ACS data using sample and\n    replication weights for accurate analysis and uncertainty estimation.\n\nI'll start with a question: **What was the median household income in\nOakland, California in 2022?**\n\n## Aggregate data with `tidycensus`\n\nAnswering that question is straightforward using *aggregate* data from\nthe U.S. Census, which provides various descriptive statistics for\naggregate geographies. I might use a web-based tool like [Census\nReporter](https://censusreporter.org/) to quickly look it up, but for an\nanalysis, I would like the data retrieval to be carried out\ntransparently via an API.\n\nIn R, the `tidycensus` package provides an easy-to-use wrapper for the\nCensus API. Note that I set up an API key for the U.S. Census and I'm\nstoring it in my `.Renviron` file as `census_api_key`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_api_key(Sys.getenv(\"census_api_key\"))\n```\n:::\n\n\n\n\nI query `B19013_001`, the median household income variable, using the\n2022 1-year American Community Survey sample and I filter down to\nOakland's GEOID, `0653000`, which is a combination of the state code for\nCalifornia, `06`, and the place code for Oakland, `53000`.[^2] I'll throw in\nthe total population variable for good measure:\n\n[^2]: See the [full variable list for the 2022 1-year\n    ACS](https://api.census.gov/data/2022/acs/acs1/variables.html) for\n    the available variables, and see the [Census Place\n    table](https://www.census.gov/library/reference/code-lists/ansi.html#place)\n    for looking up GEOIDs\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noakland_stats <- get_acs(\n  geography = \"place\",\n  variables = c(\n    median_hh_income = \"B19013_001\",\n    total_pop = \"B17001_001\"\n  ),\n  state = \"CA\",\n  year = 2022,\n  survey = \"acs1\"\n)\noakland_stats <- oakland_stats %>% filter(GEOID == '0653000')\noakland_stats %>% select(c(variable, estimate, moe))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|variable         | estimate|  moe|\n|:----------------|--------:|----:|\n|total_pop        |   426323|  811|\n|median_hh_income |    93146| 6232|\n\n</div>\n:::\n:::\n\n\n\n\nDone! We now know the population and median household income for Oakland in 2022, along with a margin of error. See [@walker_analyzing_2023] for a comprehensive treatment of working with aggregate census data.\n\n## Microdata with IPUMS\n\nWhat if I wanted to have access to the underlying data used to calculate the median? Maybe I want to try a different standard error specification for that statistic, or calculate other statistics, like the average household income. These tasks would all entail accessing census *microdata* -- household level and/or individual level census data.\n\nOne of the most popular sources for downloading census microdata is the\nUniversity of Minnesota's Integrated Public Use Microdata Series\n(IPUMS). The IPUMS team provides a centralized API for downloading\ncensus microdata, comprehensive documentation for working with the data, and harmonized variables across time [@walker_analyzing_2023,\nchapter 9].\n\nThe easiest way to access IPUMS data in R is with the [`ipumsr`](https://tech.popdata.org/ipumsr/) package,\nwhich the IPUMS team maintains [@greg_freedman_ellis_ipumsr_2024] and which allows users to submit API requests to IPUMS directly from R. To get set up, I [registered for an IPUMS API key](https://developer.ipums.org/docs/v2/get-started/), stored the key in my `.Renviron` file, and will configure the key in `ipumsr` as follows:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset_ipums_api_key(Sys.getenv(\"ipums_api_key\"))\n```\n:::\n\n\n\n\nThe `ipumsr` website [provides\ndetails](https://tech.popdata.org/ipumsr/articles/ipums.html#obtaining-data-via-the-ipums-api) on what survey products the project currently supports, as does\nthe `ipums_data_collections()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nipums_data_collections() %>%\n  filter(api_support == TRUE) %>% \n  arrange(desc(collection_type))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|collection_name     |collection_type |code_for_api |api_support |\n|:-------------------|:---------------|:------------|:-----------|\n|IPUMS USA           |microdata       |usa          |TRUE        |\n|IPUMS CPS           |microdata       |cps          |TRUE        |\n|IPUMS International |microdata       |ipumsi       |TRUE        |\n|IPUMS ATUS          |microdata       |atus         |TRUE        |\n|IPUMS AHTUS         |microdata       |ahtus        |TRUE        |\n|IPUMS MTUS          |microdata       |mtus         |TRUE        |\n|IPUMS NHIS          |microdata       |nhis         |TRUE        |\n|IPUMS MEPS          |microdata       |meps         |TRUE        |\n|IPUMS NHGIS         |aggregate data  |nhgis        |TRUE        |\n\n</div>\n:::\n:::\n\n\n\n\nI'll look at IPUMS USA since my motivating question\ninvolves median household income for a year (2022), and IPUMS USA offers\nannual data from decennial censuses 1790-2010 and American Community\nSurveys (ACS) 2000-present [@ruggles_ipums_2024]. We can check out the\nnewest products they have in the USA collection as follows:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_sample_info(collection=\"usa\") %>%\n  arrange(desc(name)) %>%\n  head(5)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|name    |description            |\n|:-------|:----------------------|\n|us2023b |2023 PRCS              |\n|us2023a |2023 ACS               |\n|us2022d |2018-2022, PRCS 5-year |\n|us2022c |2018-2022, ACS 5-year  |\n|us2022b |2022 PRCS              |\n\n</div>\n:::\n:::\n\n\n\n\nNote that \"PRCS\" refers to the Puerto Rico Community Survey (an ACS\nequivalent specifically tailored to Puerto Rico). We are principally\ninterested in the ACS, which comes in either one-year (e.g. 2023 ACS) or five-year (e.g. 2018-2022, ACS 5-year) estimates. The differences between these two estimates are described in detail in\nthe [Census Data: An\nOverview](https://walker-data.com/census-r/the-united-states-census-and-the-r-programming-language.html#census-data-an-overview)\nin [@walker_analyzing_2023]. One differentiating point is that one-year estimates come from a smaller, but more contemporary sample. In our case we'll use the\none-year to get the best sense of the 2022 income dynamics.\n\n### Step 1: Retrieving data\n\nLet's return to the motivating question for this post: **What was the\nmedian household income in Oakland, California in 2022?**\n\nTo answer that we will:  \n\n1. Get income data from the 2022 1-year ACS, \n2. Filter our data down to households in the city of Oakland, and\n3. Calculate the median.\n\nFor the first task, I'll define a general function, `retrieve_sample()` that retrieves a list of variables from a given ACS sample.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretrieve_sample <- function(sample, variables){\n  extract <- define_extract_micro(description = \"Incomes by PUMA\",\n                                  collection = \"usa\",\n                                  samples = c(sample),\n                                  variables = variables)\n  data_path <- extract %>%\n    submit_extract() %>%\n    wait_for_extract() %>%\n    download_extract(download_dir = here::here(\"data\"),\n                     overwrite = TRUE)\n  data <- read_ipums_micro(data_path)\n  return(data)\n  }\n```\n:::\n\n\n\n\nI'll also define a list of variables that I want, including `HHINCOME`\n(household income) and `INCTOT` (individual income). Some of these\nvariables refer to census-specific language – i.e. `PUMA` , `REPWT` ,\n`REPWTP`. I'll cover exactly what each of these represent later in the\npost.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariables <- list(\n  \"PUMA\",\n  \"AGE\",\n  \"SEX\",\n  \"EDUC\",\n  \"HHINCOME\",\n  \"INCTOT\",\n  \"REPWT\",\n  \"REPWTP\",\n  var_spec(\"STATEFIP\",\n           case_selections = \"06\")\n)\n```\n:::\n\n\n\n\nNote the variable, `var_spec(\"STATEFIP\", case_selections = \"06\")`. This\nselects the variable `STATEFIP`, while also specifying that we want to\nrestrict our request to data where `STATEFIP=='06'` (California). Using\n[`var_spec()`](https://tech.popdata.org/ipumsr/reference/var_spec.html)\nis important, as accidentally/unnecessarily downloading an unfiltered, full sample of the entire U.S. is time-consuming.\n\nAnyways, I can request these variables from the 2022 1-year ACS via the\nfunction call, `retrieve_sample(\"us2022a\", variables)`. However, I'll\nfirst write code that checks if I've already downloaded the data before\nrunning the query to avoid repeatedly downloading it.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlocal_ipums_extracts <- list.files(\n  path = here::here('data'),\n  pattern = \"\\\\.xml$\",\n  full.names = TRUE)\nif (length(local_ipums_extracts) > 0) {\n  existing_path <- local_ipums_extracts[1]\n  data <- read_ipums_micro(existing_path)\n} else {\n  data <- retrieve_sample(\"us2022a\", variables)\n}\n```\n:::\n\n\n\n\nHere's the resulting data, the 2022 1-year ACS for California.\n\n\n\n\n::: {#tbl-raw .cell tbl-cap='Unfiltered 2022 1-year ACS data for California'}\n\n```{.r .cell-code}\ndata %>% head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| YEAR| SAMPLE| SERIAL|    CBSERIAL| HHWT| REPWT|      CLUSTER| STATEFIP| PUMA| STRATA| GQ| HHINCOME| REPWT1| REPWT2| REPWT3| REPWT4| REPWT5| REPWT6| REPWT7| REPWT8| REPWT9| REPWT10| REPWT11| REPWT12| REPWT13| REPWT14| REPWT15| REPWT16| REPWT17| REPWT18| REPWT19| REPWT20| REPWT21| REPWT22| REPWT23| REPWT24| REPWT25| REPWT26| REPWT27| REPWT28| REPWT29| REPWT30| REPWT31| REPWT32| REPWT33| REPWT34| REPWT35| REPWT36| REPWT37| REPWT38| REPWT39| REPWT40| REPWT41| REPWT42| REPWT43| REPWT44| REPWT45| REPWT46| REPWT47| REPWT48| REPWT49| REPWT50| REPWT51| REPWT52| REPWT53| REPWT54| REPWT55| REPWT56| REPWT57| REPWT58| REPWT59| REPWT60| REPWT61| REPWT62| REPWT63| REPWT64| REPWT65| REPWT66| REPWT67| REPWT68| REPWT69| REPWT70| REPWT71| REPWT72| REPWT73| REPWT74| REPWT75| REPWT76| REPWT77| REPWT78| REPWT79| REPWT80| PERNUM| PERWT| REPWTP| FAMUNIT| RELATE| RELATED| SEX| AGE| EDUC| EDUCD| INCTOT| REPWTP1| REPWTP2| REPWTP3| REPWTP4| REPWTP5| REPWTP6| REPWTP7| REPWTP8| REPWTP9| REPWTP10| REPWTP11| REPWTP12| REPWTP13| REPWTP14| REPWTP15| REPWTP16| REPWTP17| REPWTP18| REPWTP19| REPWTP20| REPWTP21| REPWTP22| REPWTP23| REPWTP24| REPWTP25| REPWTP26| REPWTP27| REPWTP28| REPWTP29| REPWTP30| REPWTP31| REPWTP32| REPWTP33| REPWTP34| REPWTP35| REPWTP36| REPWTP37| REPWTP38| REPWTP39| REPWTP40| REPWTP41| REPWTP42| REPWTP43| REPWTP44| REPWTP45| REPWTP46| REPWTP47| REPWTP48| REPWTP49| REPWTP50| REPWTP51| REPWTP52| REPWTP53| REPWTP54| REPWTP55| REPWTP56| REPWTP57| REPWTP58| REPWTP59| REPWTP60| REPWTP61| REPWTP62| REPWTP63| REPWTP64| REPWTP65| REPWTP66| REPWTP67| REPWTP68| REPWTP69| REPWTP70| REPWTP71| REPWTP72| REPWTP73| REPWTP74| REPWTP75| REPWTP76| REPWTP77| REPWTP78| REPWTP79| REPWTP80|\n|----:|------:|------:|-----------:|----:|-----:|------------:|--------:|----:|------:|--:|--------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|------:|-----:|------:|-------:|------:|-------:|---:|---:|----:|-----:|------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|\n| 2022| 202201|  74692| 2.02201e+12|   14|     1| 2.022001e+12|        6| 6509| 650906|  4|  9999999|     12|     14|     14|     12|     14|     14|     12|     12|     11|      12|      13|      13|      11|      13|      13|      11|      13|      12|      12|      14|      13|      13|      13|      13|      11|      11|      13|      12|      14|      13|      10|      12|      13|      10|      13|      13|      15|      12|      14|      14|      12|      11|      12|      12|      10|      14|      13|      13|      12|      12|      11|      13|      12|      11|      12|      14|      13|      12|      14|      12|      13|      13|      12|      12|      12|      12|      12|      12|      12|      11|      12|      13|      13|      11|      14|      12|      11|      11|      13|      10|      1|    14|      1|       1|     12|    1270|   2|  56|    6|    64|  14500|      12|      14|      14|      12|      14|      14|      12|      12|      11|       12|       13|       13|       11|       13|       13|       11|       13|       12|       12|       14|       13|       13|       13|       13|       11|       11|       13|       12|       14|       13|       10|       12|       13|       10|       13|       13|       15|       12|       14|       14|       12|       11|       12|       12|       10|       14|       13|       13|       12|       12|       11|       13|       12|       11|       12|       14|       13|       12|       14|       12|       13|       13|       12|       12|       12|       12|       12|       12|       12|       11|       12|       13|       13|       11|       14|       12|       11|       11|       13|       10|\n| 2022| 202201|  74693| 2.02201e+12|   27|     1| 2.022001e+12|        6| 6501| 650106|  3|  9999999|     27|     28|     48|     49|      5|     47|     26|     26|      6|       7|       6|      28|      26|      48|       6|      28|      47|      27|      26|      44|      50|      50|      25|      28|      27|      27|       6|      47|      25|      27|      29|       6|      49|      27|      27|       6|      29|       6|       6|      26|      28|      28|       6|       6|      51|       6|      26|      27|      48|      46|      47|      28|      27|       6|      51|      27|       6|      26|      29|       4|       6|       6|      28|      27|      29|      27|      48|       5|      27|      29|      27|      46|       6|      25|      27|      48|      27|      43|      47|      25|      1|    27|      1|       1|     13|    1301|   1|  52|    0|     2|      0|      27|      28|      48|      49|       5|      47|      26|      26|       6|        7|        6|       28|       26|       48|        6|       28|       47|       27|       26|       44|       50|       50|       25|       28|       27|       27|        6|       47|       25|       27|       29|        6|       49|       27|       27|        6|       29|        6|        6|       26|       28|       28|        6|        6|       51|        6|       26|       27|       48|       46|       47|       28|       27|        6|       51|       27|        6|       26|       29|        4|        6|        6|       28|       27|       29|       27|       48|        5|       27|       29|       27|       46|        6|       25|       27|       48|       27|       43|       47|       25|\n| 2022| 202201|  74694| 2.02201e+12|   70|     1| 2.022001e+12|        6| 8101| 810106|  3|  9999999|     19|     11|     11|     59|     71|     71|     71|     71|     78|      91|      89|      91|      19|      57|      80|      89|      70|      78|      90|      11|      20|      12|      11|      58|      70|      71|      71|      71|      80|      91|      90|      91|      18|      60|      79|      89|      70|      79|      89|      92|      80|      92|      90|      90|      71|      72|      69|      71|      20|      11|      11|      59|      80|      92|      19|      58|      71|      18|      58|      90|      79|      90|      90|      90|      70|      69|      70|      71|      20|      12|      10|      57|      78|      91|      20|      58|      71|      20|      56|      12|      1|    70|      1|       1|     13|    1301|   1|  61|    7|    71|     80|      19|      11|      11|      59|      71|      71|      71|      71|      78|       91|       89|       91|       19|       57|       80|       89|       70|       78|       90|       11|       20|       12|       11|       58|       70|       71|       71|       71|       80|       91|       90|       91|       18|       60|       79|       89|       70|       79|       89|       92|       80|       92|       90|       90|       71|       72|       69|       71|       20|       11|       11|       59|       80|       92|       19|       58|       71|       18|       58|       90|       79|       90|       90|       90|       70|       69|       70|       71|       20|       12|       10|       57|       78|       91|       20|       58|       71|       20|       56|       12|\n| 2022| 202201|  74695| 2.02201e+12|   22|     1| 2.022001e+12|        6| 8303| 830306|  4|  9999999|     22|     26|     29|     36|      2|     32|     36|     27|      3|       2|       4|      22|      18|      55|       3|      22|      43|      18|      27|       4|       2|       3|      19|      26|      20|      20|      46|       5|      21|      23|      20|      38|       2|      27|      23|      45|      20|      31|      53|      20|      20|      20|      54|      42|       6|      49|      16|      19|       3|       3|       4|      21|      27|      33|       4|      25|      37|      29|      18|       2|       4|       3|      29|      18|      27|      28|      34|       2|      26|      23|      22|      38|       5|      19|      21|      35|      25|      56|      30|      24|      1|    22|      1|       1|     12|    1270|   2|  26|    7|    71|   9000|      22|      26|      29|      36|       2|      32|      36|      27|       3|        2|        4|       22|       18|       55|        3|       22|       43|       18|       27|        4|        2|        3|       19|       26|       20|       20|       46|        5|       21|       23|       20|       38|        2|       27|       23|       45|       20|       31|       53|       20|       20|       20|       54|       42|        6|       49|       16|       19|        3|        3|        4|       21|       27|       33|        4|       25|       37|       29|       18|        2|        4|        3|       29|       18|       27|       28|       34|        2|       26|       23|       22|       38|        5|       19|       21|       35|       25|       56|       30|       24|\n| 2022| 202201|  74696| 2.02201e+12|    8|     1| 2.022001e+12|        6| 6712| 671206|  3|  9999999|      9|     15|     10|      8|      8|      2|      2|      8|      2|      15|       1|      16|       8|      14|      15|      10|       8|       7|       9|      10|      14|       9|       3|      16|      16|       9|      10|       1|       7|       8|       8|       8|       3|       9|      10|      16|      15|       1|       1|       8|      16|       9|       2|      15|      15|       9|       8|       1|       8|       8|       8|       8|       1|       9|       8|      15|      16|       3|       2|       2|       8|      15|       8|       8|       8|       1|       1|       9|       2|      16|       3|      15|       8|      14|      17|       9|       8|       8|       8|       3|      1|     8|      1|       1|     13|    1301|   2|  38|    6|    63|  48000|       9|      15|      10|       8|       8|       2|       2|       8|       2|       15|        1|       16|        8|       14|       15|       10|        8|        7|        9|       10|       14|        9|        3|       16|       16|        9|       10|        1|        7|        8|        8|        8|        3|        9|       10|       16|       15|        1|        1|        8|       16|        9|        2|       15|       15|        9|        8|        1|        8|        8|        8|        8|        1|        9|        8|       15|       16|        3|        2|        2|        8|       15|        8|        8|        8|        1|        1|        9|        2|       16|        3|       15|        8|       14|       17|        9|        8|        8|        8|        3|\n| 2022| 202201|  74697| 2.02201e+12|   49|     1| 2.022001e+12|        6| 7301| 730106|  4|  9999999|     52|     51|     47|      5|     79|     45|     45|      4|     49|       5|       3|     103|      91|      53|      49|      49|      46|       5|     102|      88|      47|      48|      55|       4|      98|      49|      47|       5|      44|       5|       3|      93|     104|      48|      54|      46|      53|       4|     103|       3|      46|      50|      51|      93|       4|      48|      50|      77|      49|      93|     108|       5|       4|      46|      47|      51|      57|      89|       4|       4|      54|      42|      56|     101|       4|      45|      55|      94|      48|      96|      99|       5|       4|      42|      49|      47|      50|      75|       4|      90|      1|    49|      1|       1|     12|    1270|   1|  23|    6|    63|  24000|      52|      51|      47|       5|      79|      45|      45|       4|      49|        5|        3|      103|       91|       53|       49|       49|       46|        5|      102|       88|       47|       48|       55|        4|       98|       49|       47|        5|       44|        5|        3|       93|      104|       48|       54|       46|       53|        4|      103|        3|       46|       50|       51|       93|        4|       48|       50|       77|       49|       93|      108|        5|        4|       46|       47|       51|       57|       89|        4|        4|       54|       42|       56|      101|        4|       45|       55|       94|       48|       96|       99|        5|        4|       42|       49|       47|       50|       75|        4|       90|\n\n</div>\n:::\n:::\n\n\n\n\n### Step 2: Using Geocorr to Identify Geographies\n\nWe now have microdata for all of California, but we need to filter down\nto just Oakland. Unfortunately, this isn't as simple as just running\n`filter(CITY == 'Oakland')` -- ACS microdata does not include a field\nfor explicitly identifying cities (note that a city is typically\nreferred to as a \"place\" in census data).\n\nThe smallest geographic area explicitly identified in the microdata is\nsomething called a public use microdata area (PUMA) [@pastoor_how_2024].\nPUMAS are unique geographies that always aggregate to the state-level\n(e.g. California can be constructed with a collection of PUMAs), but\nonly sometimes aggregate to other small geographic areas, such as city,\nmetro area, and county [See [Census\nHierarchies](https://walker-data.com/census-r/the-united-states-census-and-the-r-programming-language.html#census-hierarchies)\nin @walker_analyzing_2023, chapter 1].\n\nTo find out if a city corresponds to a collection of PUMAs and which\nPUMAs those are, we'll use\n[Geocorr](https://mcdc.missouri.edu/applications/geocorr2022.html)\n(geographic correspondence engine), an application that generates\ncorrelation lists showing relationships between two or more geographic\ncoverages in the United States [@mihalik_missouri_2022]. Geocorr is a\nsponsored program of the Missouri State library and published by the\nUniversity of Missouri Center for Health Policy.[^3]\n\n[^3]: I'll to note that the combination of IPUMS and Geocorr\n    is a fantastic public good, and it's extremely generous of the\n    public Universities of Minnesota and Missouri to publish these.\n\n![Geocorr 2022: Geographic Correspondence\nEngine](geocorr.png){width=\"80%\"}\n\nTo use Geocorr, I'll define a function, `geocorr_2022()` that queries\nGeocorr 2022 and retrieves a .csv file establishing the relationships\nbetween two sets of geographies within a given state.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngeocorr_2022 <- function(state, geo_1, geo_2, weight_var) {\n  base_url <- \"https://mcdc.missouri.edu\"\n  params <- glue(\n    \"cgi-bin/broker?_PROGRAM=apps.geocorr2022.sas&\",\n    \"_SERVICE=MCDC_long&_debug=0&\",\n    \"state={state}&g1_={geo_1}&g2_={geo_2}&wtvar={weight_var}&\",\n    \"nozerob=1&fileout=1&filefmt=csv&lstfmt=txt&title=&\",\n    \"counties=&metros=&places=&oropt=&latitude=&longitude=&\",\n    \"distance=&kiloms=0&locname=\")\n  initial_url <- params %>% url_absolute(base = base_url)\n  initial_response <- GET(initial_url)\n  html_content <- content(initial_response, as = \"text\")\n  parsed_html <- read_html(html_content)\n  # Extract the one link\n  csv_url <- parsed_html %>%\n    html_node(\"a\") %>%\n    html_attr(\"href\") %>%\n    stringr::str_trim() %>%\n    url_absolute(base = base_url)\n  csv_data <- read_csv(csv_url)\n  return(csv_data)\n}\n```\n:::\n\n\n\n\nWe'll use that function to establish the relationships between\nCalifornia's 2022 PUMAs and its \"places,\" using individual population as\nmeasured in the 2020 Decenial Census to weight the relationships.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncsv_data <- geocorr_2022(\"Ca06\", \"puma22\", \"place\", \"pop20\")\n```\n:::\n\n\n\n\nWith that, we can see which PUMAs correspond to the City of Oakland.\n\n\n\n\n::: {#tbl-correspondence .cell tbl-cap='PUMA to Place correspondence for Oakand, CA'}\n\n```{.r .cell-code}\ncsv_data %>%\n  select(-c(state, stab, place, PUMA22name)) %>%\n  filter(PlaceName == 'Oakland city, CA')\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|puma22 |PlaceName        |pop20  |afact |\n|:------|:----------------|:------|:-----|\n|00111  |Oakland city, CA |106433 |1     |\n|00112  |Oakland city, CA |106896 |1     |\n|00113  |Oakland city, CA |125840 |1     |\n|00114  |Oakland city, CA |9      |0     |\n|00123  |Oakland city, CA |101468 |1     |\n\n</div>\n:::\n:::\n\n\n\n\nThe `AFACT` (allocation factor) column shows the proportion of the\nsource area contained in the target area -- in this case the proportion\nof the PUMA population that belongs to Oakland. In this case, 100% of\nthe populations in PUMAs 111, 112, 113, and 123 belong to Oakland, and\n0% of PUMA 114. GEOCORR does believe that 9 individuals from 114 live in\nOakland, but based on the AFACT of 0, I'll feel comfortable dropping\nthat PUMA.[^4]\n\n[^4]: Were the AFACT higher, e.g. 1%, I would randomly sample 1% of the\n    individuals from that PUMA and include them in my Oakland sample.\n\nFiltering to those PUMAs gets us the 2022 1-year ACS microdata for the\nCity of Oakland (note the use of `haven::zap_labels()` is just to remove\nsome unnecessary formatting that comes with the data).\n\n\n\n\n::: {#tbl-oakland-raw .cell tbl-cap='2022 1-year ACS data for Oakland, CA'}\n\n```{.r .cell-code}\noakland_pumas <- c(111, 112, 113, 123)\noak <- data %>%\n  filter(PUMA %in% oakland_pumas) %>% \n  haven::zap_labels()\noak %>% head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| YEAR| SAMPLE| SERIAL|    CBSERIAL| HHWT| REPWT|      CLUSTER| STATEFIP| PUMA| STRATA| GQ| HHINCOME| REPWT1| REPWT2| REPWT3| REPWT4| REPWT5| REPWT6| REPWT7| REPWT8| REPWT9| REPWT10| REPWT11| REPWT12| REPWT13| REPWT14| REPWT15| REPWT16| REPWT17| REPWT18| REPWT19| REPWT20| REPWT21| REPWT22| REPWT23| REPWT24| REPWT25| REPWT26| REPWT27| REPWT28| REPWT29| REPWT30| REPWT31| REPWT32| REPWT33| REPWT34| REPWT35| REPWT36| REPWT37| REPWT38| REPWT39| REPWT40| REPWT41| REPWT42| REPWT43| REPWT44| REPWT45| REPWT46| REPWT47| REPWT48| REPWT49| REPWT50| REPWT51| REPWT52| REPWT53| REPWT54| REPWT55| REPWT56| REPWT57| REPWT58| REPWT59| REPWT60| REPWT61| REPWT62| REPWT63| REPWT64| REPWT65| REPWT66| REPWT67| REPWT68| REPWT69| REPWT70| REPWT71| REPWT72| REPWT73| REPWT74| REPWT75| REPWT76| REPWT77| REPWT78| REPWT79| REPWT80| PERNUM| PERWT| REPWTP| FAMUNIT| RELATE| RELATED| SEX| AGE| EDUC| EDUCD| INCTOT| REPWTP1| REPWTP2| REPWTP3| REPWTP4| REPWTP5| REPWTP6| REPWTP7| REPWTP8| REPWTP9| REPWTP10| REPWTP11| REPWTP12| REPWTP13| REPWTP14| REPWTP15| REPWTP16| REPWTP17| REPWTP18| REPWTP19| REPWTP20| REPWTP21| REPWTP22| REPWTP23| REPWTP24| REPWTP25| REPWTP26| REPWTP27| REPWTP28| REPWTP29| REPWTP30| REPWTP31| REPWTP32| REPWTP33| REPWTP34| REPWTP35| REPWTP36| REPWTP37| REPWTP38| REPWTP39| REPWTP40| REPWTP41| REPWTP42| REPWTP43| REPWTP44| REPWTP45| REPWTP46| REPWTP47| REPWTP48| REPWTP49| REPWTP50| REPWTP51| REPWTP52| REPWTP53| REPWTP54| REPWTP55| REPWTP56| REPWTP57| REPWTP58| REPWTP59| REPWTP60| REPWTP61| REPWTP62| REPWTP63| REPWTP64| REPWTP65| REPWTP66| REPWTP67| REPWTP68| REPWTP69| REPWTP70| REPWTP71| REPWTP72| REPWTP73| REPWTP74| REPWTP75| REPWTP76| REPWTP77| REPWTP78| REPWTP79| REPWTP80|\n|----:|------:|------:|-----------:|----:|-----:|------------:|--------:|----:|------:|--:|--------:|------:|------:|------:|------:|------:|------:|------:|------:|------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|------:|-----:|------:|-------:|------:|-------:|---:|---:|----:|-----:|------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|\n| 2022| 202201|  74718| 2.02201e+12|    5|     1| 2.022001e+12|        6|  111|  11106|  3|  9999999|      5|      4|      5|      4|      5|      5|      5|      2|      6|       5|       5|       3|       5|       2|       2|       5|       4|       4|       4|       5|       4|       4|       5|       5|       4|       5|       5|       2|       2|       2|       5|       4|       5|       3|       3|       4|       5|       5|       4|       3|       5|       5|       4|       5|       5|       5|       4|       2|       5|       4|       4|       4|       5|       2|       3|       4|       5|       5|       4|       5|       5|       4|       5|       5|       4|       5|       5|       2|       2|       3|       3|       4|       4|       2|       2|       5|       4|       4|       5|       4|      1|     5|      1|       1|     13|    1301|   1|  20|    7|    71|      0|       5|       4|       5|       4|       5|       5|       5|       2|       6|        5|        5|        3|        5|        2|        2|        5|        4|        4|        4|        5|        4|        4|        5|        5|        4|        5|        5|        2|        2|        2|        5|        4|        5|        3|        3|        4|        5|        5|        4|        3|        5|        5|        4|        5|        5|        5|        4|        2|        5|        4|        4|        4|        5|        2|        3|        4|        5|        5|        4|        5|        5|        4|        5|        5|        4|        5|        5|        2|        2|        3|        3|        4|        4|        2|        2|        5|        4|        4|        5|        4|\n| 2022| 202201|  74737| 2.02201e+12|   56|     1| 2.022001e+12|        6|  111|  11106|  3|  9999999|      6|     81|     56|     66|     67|     81|     65|      7|     55|      80|      79|      11|      55|      83|      43|      12|       6|      42|      56|      56|       7|      82|      56|      65|      66|      79|      65|       7|      56|      81|      80|      12|      55|      83|      42|      12|       6|      43|      55|      55|       7|      82|      55|      68|      68|      81|      67|       6|      56|      78|      80|      12|      55|      82|      43|      11|       6|      42|      56|      54|       6|      82|      56|      66|      67|      78|      67|       6|      56|      81|      80|      12|      55|      82|      44|      12|       7|      43|      54|      55|      1|    56|      1|       1|     13|    1301|   1|  56|    6|    63|    480|       6|      81|      56|      66|      67|      81|      65|       7|      55|       80|       79|       11|       55|       83|       43|       12|        6|       42|       56|       56|        7|       82|       56|       65|       66|       79|       65|        7|       56|       81|       80|       12|       55|       83|       42|       12|        6|       43|       55|       55|        7|       82|       55|       68|       68|       81|       67|        6|       56|       78|       80|       12|       55|       82|       43|       11|        6|       42|       56|       54|        6|       82|       56|       66|       67|       78|       67|        6|       56|       81|       80|       12|       55|       82|       44|       12|        7|       43|       54|       55|\n| 2022| 202201|  74738| 2.02201e+12|   15|     1| 2.022001e+12|        6|  113|  11306|  4|  9999999|     15|     13|     15|     15|     15|     15|     14|     15|     13|      15|      15|      15|      14|      15|      15|      13|      14|      13|      15|      17|      13|      15|      17|      15|      14|      13|      14|      14|      17|      15|      14|      14|      15|      12|      14|      15|      16|      15|      15|      16|      13|      15|      15|      15|      14|      15|      13|      14|      13|      13|      12|      14|      15|      12|      13|      15|      16|      15|      15|      12|      13|      15|      15|      15|      15|      14|      15|      15|      14|      15|      15|      15|      15|      15|      16|      13|      14|      12|      14|      13|      1|    15|      1|       1|     12|    1270|   1|  34|    6|    63|   1200|      15|      13|      15|      15|      15|      15|      14|      15|      13|       15|       15|       15|       14|       15|       15|       13|       14|       13|       15|       17|       13|       15|       17|       15|       14|       13|       14|       14|       17|       15|       14|       14|       15|       12|       14|       15|       16|       15|       15|       16|       13|       15|       15|       15|       14|       15|       13|       14|       13|       13|       12|       14|       15|       12|       13|       15|       16|       15|       15|       12|       13|       15|       15|       15|       15|       14|       15|       15|       14|       15|       15|       15|       15|       15|       16|       13|       14|       12|       14|       13|\n| 2022| 202201|  75005| 2.02201e+12|   38|     1| 2.022001e+12|        6|  113|  11306|  4|  9999999|     36|     38|     36|     37|     35|     36|     38|     39|     33|      39|      37|      37|      37|      37|      37|      36|      37|      35|      39|      37|      37|      34|      36|      37|      38|      35|      36|      35|      39|      35|      36|      34|      38|      37|      36|      38|      36|      36|      36|      36|      35|      36|      39|      36|      36|      37|      37|      37|      38|      35|      33|      38|      36|      34|      36|      37|      35|      37|      37|      36|      35|      39|      37|      39|      37|      38|      38|      36|      37|      37|      37|      35|      37|      37|      35|      37|      35|      37|      37|      37|      1|    38|      1|       1|     12|    1270|   2|  40|    2|    23|  41300|      36|      38|      36|      37|      35|      36|      38|      39|      33|       39|       37|       37|       37|       37|       37|       36|       37|       35|       39|       37|       37|       34|       36|       37|       38|       35|       36|       35|       39|       35|       36|       34|       38|       37|       36|       38|       36|       36|       36|       36|       35|       36|       39|       36|       36|       37|       37|       37|       38|       35|       33|       38|       36|       34|       36|       37|       35|       37|       37|       36|       35|       39|       37|       39|       37|       38|       38|       36|       37|       37|       37|       35|       37|       37|       35|       37|       35|       37|       37|       37|\n| 2022| 202201|  75119| 2.02201e+12|   20|     1| 2.022001e+12|        6|  111|  11106|  3|  9999999|     22|     21|     21|     22|     20|     20|     21|     21|     20|      22|      22|      22|      20|      22|      21|      21|      22|      22|      20|      22|      22|      22|      22|      22|      20|      21|      20|      22|      21|      21|      20|      22|      21|      22|      22|      20|      21|      22|      22|      22|      20|      22|      22|      22|      21|      21|      22|      22|      21|      22|      21|      20|      22|      21|      20|      20|      22|      23|      21|      22|      22|      22|      22|      20|      20|      22|      22|      21|      22|      22|      22|      21|      20|      22|      22|      20|      20|      22|      22|      22|      1|    20|      1|       1|     13|    1301|   2|  88|    2|    23|   5800|      22|      21|      21|      22|      20|      20|      21|      21|      20|       22|       22|       22|       20|       22|       21|       21|       22|       22|       20|       22|       22|       22|       22|       22|       20|       21|       20|       22|       21|       21|       20|       22|       21|       22|       22|       20|       21|       22|       22|       22|       20|       22|       22|       22|       21|       21|       22|       22|       21|       22|       21|       20|       22|       21|       20|       20|       22|       23|       21|       22|       22|       22|       22|       20|       20|       22|       22|       21|       22|       22|       22|       21|       20|       22|       22|       20|       20|       22|       22|       22|\n| 2022| 202201|  75131| 2.02201e+12|   11|     1| 2.022001e+12|        6|  123|  12306|  3|  9999999|     12|      0|      8|     20|      8|      0|      1|     14|     14|       1|      16|      11|      13|      20|       8|      14|       0|       8|      13|      12|      11|      15|       8|       1|      10|      13|      17|      15|      12|      19|       1|      12|       0|       1|       8|       1|      16|       8|      12|      10|      11|       1|       9|      21|       7|       0|       1|      13|      14|       1|      16|      10|      13|      18|      10|      13|       1|       9|      14|      11|      10|      13|       9|       1|       9|      15|      17|      15|      13|      19|       0|      14|       0|       1|       9|       1|      16|       9|      11|       9|      1|    11|      1|       1|     13|    1301|   2|  86|    2|    23|      0|      12|       0|       8|      20|       8|       0|       1|      14|      14|        1|       16|       11|       13|       20|        8|       14|        0|        8|       13|       12|       11|       15|        8|        1|       10|       13|       17|       15|       12|       19|        1|       12|        0|        1|        8|        1|       16|        8|       12|       10|       11|        1|        9|       21|        7|        0|        1|       13|       14|        1|       16|       10|       13|       18|       10|       13|        1|        9|       14|       11|       10|       13|        9|        1|        9|       15|       17|       15|       13|       19|        0|       14|        0|        1|        9|        1|       16|        9|       11|        9|\n\n</div>\n:::\n:::\n\n\n\n\n### Step 3: Filtering to desired granularity\n\nEach row in the ACS microdata is an individual, identified by a unique\ncombination of `SAMPLE`, which defines the year when the individual was\nsurveyed, `SERIAL`, a unique identifier for that individual's household,\nand `PERNUM`, a unique identifier for the individual within their\nhousehold [@ruggles_ipums_2024]. Thus, we can identify units as follows:\n\n-   **Households**: The combination of `SAMPLE` and `SERIAL` provides a\n    unique identifier for every household in the IPUMS\n-   **Individuals**: The combination of `SAMPLE`, `SERIAL`, and `PERNUM`\n    provides a unique identifier for every person in the IPUMS\n\nWe can group by these variable combinations and see how many individuals\nand households were surveyed across PUMAs in Oakland for the 2022 1-year\nACS. We can see that each row in the data represents an individual\n(`n_rows` equals `n_individuals`) and, as we would expect, the number of\nhouseholds is much lower than the number of individuals.\n\n\n\n\n::: {#tbl-granularity .cell tbl-cap='Oakland Dataset Granularity by PUMA'}\n\n```{.r .cell-code}\noak %>% group_by(PUMA) %>% summarise(\n  n_rows = n(),\n  n_individuals = n_distinct(SAMPLE, SERIAL, PERNUM),\n  n_households = n_distinct(SAMPLE, SERIAL)\n  )\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| PUMA| n_rows| n_individuals| n_households|\n|----:|------:|-------------:|------------:|\n|  111|   1083|          1083|          578|\n|  112|   1152|          1152|          547|\n|  113|    989|           989|          385|\n|  123|    905|           905|          389|\n\n</div>\n:::\n:::\n\n\n\n\nI'll also randomly select a household in the data to see what such a\nunit looks like in practice.\n\n\n\n\n::: {#tbl-example-hh .cell tbl-cap='An example household with income data'}\n\n```{.r .cell-code  code-fold=\"true\"}\nhousehold_serials <- oak %>%\n  group_by(SERIAL) %>%\n  count() %>%\n  filter(n > 1) %>%\n  pull(SERIAL)\nset.seed(2)\nsample_household <- sample(household_serials, 1)\nn <- oak %>% filter(SERIAL == sample_household) %>% dim() %>% .[1]\noak %>% filter(SERIAL == sample_household) %>% \n  select(c(SERIAL, PERNUM, AGE, SEX, HHINCOME, INCTOT))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| SERIAL| PERNUM| AGE| SEX| HHINCOME|  INCTOT|\n|------:|------:|---:|---:|--------:|-------:|\n| 211975|      1|  31|   2|    27300|    9300|\n| 211975|      2|  13|   1|    27300| 9999999|\n| 211975|      3|   3|   2|    27300| 9999999|\n| 211975|      4|  27|   1|    27300|   18000|\n\n</div>\n:::\n:::\n\n\n\n\nHere we can see that this household, with `SERIAL`\n211975 has 4 members,\neach with a unique `PERNUM`.\n\nLet's return to the motivating question – **what was the median\nhousehold income in Oakland, California in 2022?** Note the income\nvariables we observe for this family:\n\n1.  `INCTOT` reports each respondent's total pre-tax personal income or\n    losses from all sources for the previous year. `9999999` is code to\n    denote that the value is missing, which makes sense given that the\n    missing values above correspond to children in the household [See\n    [INCTOT](https://usa.ipums.org/usa-action/variables/INCTOT) in\n    @ruggles_ipums_2024].\n\n2.  `HHINCOME` reports the total money income of all household members\n    age 15+ during the previous year. The amount should equal the sum of\n    all household members' individual incomes, as recorded in the\n    person-record variable INCTOT [See\n    [HHINCOME](https://usa.ipums.org/usa-action/variables/HHINCOME) in\n    @ruggles_ipums_2024]\n\nGiven what we know about the unique identifier for households, and the\n`HHINCOME` variable, we can construct the appropriate dataset for\nanswering our motivating question – every household in Oakland that had\nhousehold income.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhouseholds_w_income <- oak %>%\n  distinct(SAMPLE, SERIAL, .keep_all = TRUE) %>% \n  filter(HHINCOME != 9999999, HHINCOME >= 0)\n```\n:::\n\n\n\n\nIt seems we can proceed to simply calculate the median of the `HHINCOME`\ncolumn? Not so fast... Data in the ACS microdata are not what they seem.\nBefore we do any analysis, we have to account for **sample weights**.\n\n### Step 4: Applying sample weights\n\nLet's return to our sample family from above, but also examine the\nvariables `PERWT` and `HHWT`.\n\n\n\n\n::: {#tbl-example-hh-weights .cell tbl-cap='An example household with weight data'}\n\n```{.r .cell-code}\noak %>% filter(SERIAL == sample_household) %>% \n  select(c(AGE, SEX, HHINCOME, INCTOT, PERWT, HHWT))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| AGE| SEX| HHINCOME|  INCTOT| PERWT| HHWT|\n|---:|---:|--------:|-------:|-----:|----:|\n|  31|   2|    27300|    9300|    62|   62|\n|  13|   1|    27300| 9999999|    60|   62|\n|   3|   2|    27300| 9999999|   120|   62|\n|  27|   1|    27300|   18000|    63|   62|\n\n</div>\n:::\n:::\n\n\n\n\nThese are the two primary sample weights in ACS microdata, and they can\nbe interpreted fairly directly. `PERWT` gives the population represented\nby each individual in the sample, thus in the first row of the sample\nhousehold, the 31 year old woman with an individual income of \\$9,300\nrepresents 62 individuals in the PUMA. `HHWT` gives the number of\nhouseholds in the general population represented by each household in\nthe sample, thus this household is representative of 62 households in\nthat PUMA.\n\nAny person-level analysis of ACS microdata should be weighted by\n`PERWT`, and household-level analysis should be weighted by `HHWT` [See\n[Sample Weights](https://usa.ipums.org/usa/intro.shtml#weights) in\n@ruggles_ipums_2024]. We'll use the\n[`srvyr`](http://gdfe.co/srvyr/reference/index.html) package for easily\ndefining the survey weights and using them to calculate summary\nstatistics.\n\nHere we'll finally address the motivating question. **The median\nhousehold income in Oakland in 2022** as measured in the IPUMS microdata\nwas as follows:\n\n\n\n\n::: {#tbl-answer .cell tbl-cap='2022 Median Household Income in Oakland, CA'}\n\n```{.r .cell-code}\nhouseholds_w_income %>%\n  as_survey(weights=HHWT) %>%\n  summarise(weighted_median = survey_median(HHINCOME)) %>% \n  select(weighted_median)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| weighted_median|\n|---------------:|\n|           89000|\n\n</div>\n:::\n:::\n\n\n\n\nLet's do a quick comparison of our IPUMS results to the aggregate census\ndata we retrieved in the first section. Here are our full IPUMS results\nfor both median household income and population:\n\n\n\n\n::: {#tbl-ipums-res .cell tbl-cap='IPUMS versus ACS aggregate results'}\n\n```{.r .cell-code  code-fold=\"true\"}\nmedian_table <- households_w_income %>%\n  as_survey(weights=HHWT) %>% \n  summarise(weighted_median = survey_median(HHINCOME)) %>% \n  mutate(variable = \"median_hh_income\",\n         ipums_estimate = weighted_median,\n         se = weighted_median_se)\n\ncount_table <- oak %>%\n  as_survey(weights=PERWT) %>% \n  survey_count() %>% \n  mutate(variable = \"total_pop\",\n         ipums_estimate = n,\n         se = n_se)\n\naggregate_data <- oakland_stats %>%\n  select(c(variable, estimate)) %>%\n  rename(ACS_aggregate_estimate = estimate)\n\nbind_rows(count_table, median_table) %>% \n  select(c(variable, ipums_estimate)) %>% inner_join(aggregate_data, by='variable')\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|variable         | ipums_estimate| ACS_aggregate_estimate|\n|:----------------|--------------:|----------------------:|\n|total_pop        |         430052|                 426323|\n|median_hh_income |          89000|                  93146|\n\n</div>\n:::\n:::\n\n\n\n\nThese are clearly different. What gives? Unfortunately, **summary\nstatistics calculated using IPUMS data typically cannot match aggregate\nACS figures!**\n\nOne major reason for this gap is additional sampling error. Recall that\nthe American Community Survey is a sample. A given one-year ACS is\ntypically a 1% sample of the U.S. population, with associated sampling\nerror. When the census makes microdata available, they create a sample\nof that sample -- we do not get the full 1%. This second sampling\nprocess introduces further sampling error in the microdata that is not\nreflected in figures sourced from aggregate ACS data, which are\ncalculated using the full ACS sample [[See\nACS](https://usa.ipums.org/usa/chapter2/chapter2.shtml#ACS) in\n@ruggles_ipums_2024]. This introduces its own, additional sampling\nerror.[^5]\n\n[^5]: Beyond that sampling error, the census applies various other\n    additional data processing steps to microdata that aren't applied to\n    aggregate figures [[See\n    ACS](https://usa.ipums.org/usa/chapter2/chapter2.shtml#ACS) in\n    @ruggles_ipums_2024]\n\n### Step 5: Calculating Standard Errors\n\nNow we have estimates derived from the ACS microdata, but recall that this is survey data. We are working with a small sample of Oakland's population, so we would assume that our estimates are likely going to be wrong by some degree, so accurately communicating uncertainty via good standard errors will be important.  \n\nFor the sake of this example, let's explore the problem of standard errors via a slightly different motivating question -- **what was the average household income in Oakland in 2022**? I'm switching to the average because we are about to calculate some standard errors from-scratch, and that's much more clear-cut for linear statistics like the average than for non-linear statistics like the median. We will return to the median at the end of this section, but rely on a package implementation and not do anything from-scratch.\n\nAnyways, let's calculate the average household income in Oakland using the sample household weights. The [formula for the weighted average](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Mathematical_definition) is: \n$$\n\\bar{X}_w = \\frac{\\sum_{i=1}^{n}w_ix_i}{\\sum_{i=1}^{n}w_i}\n$$\nWe'll put that into code and get the following estimate of the average household income in Oakland:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweighted_mean <- (\n  sum(households_w_income$HHINCOME * households_w_income$HHWT)\n  / sum(households_w_income$HHWT)\n  )\nweighted_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 141001.2\n```\n\n\n:::\n:::\n\n\n\nNow, let's get a standard error for that estimate. Correctly utilizing the sample weights in the variance calculation is [a little tricky](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Variance) and there are a few different approaches. Most packages (e.g. [SAS](https://documentation.sas.com/doc/en/statug/latest/statug_surveymeans_details06.htm#statug.surveymeans.variancedetails), [Stata](https://www.stata.com/manuals/svyvarianceestimation.pdf), and R's [`survey` package](https://r-survey.r-forge.r-project.org/survey/#:~:text=Variances%20by%20Taylor%20linearization)) default to using \"linearized variance.\" In short, this entails calculating the first-order Taylor series approximation of the weighted mean formula above, then finding the variance of that approximation. Wikipedia has a nice [walkthrough of that calculation](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Variance_of_the_weighted_mean_(%CF%80-estimator_for_ratio-mean)), but the details are beyond the scope of this post -- we will just work with the resulting formula, the variance and standard error of the first-order linear approximation of the weighted mean:\n\n$$\n\\begin{align*}\n\\hat{\\text{Var}}(\\bar{X}_w) &= \\frac{\\sum w_i^2 (x_i - \\bar{X}_w)^2}{\\left(\\sum w_i\\right)^2} \\\\\n\\hat{\\text{SE}}(\\bar{X}_w) &= \\sqrt{\\hat{\\text{Var}}(\\bar{X}_w)}\n\\end{align*}\n\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnumerator <- sum(households_w_income$HHWT^2 * (households_w_income$HHINCOME - weighted_mean)^2)\ndenominator <- sum(households_w_income$HHWT)^2\nvariance <- numerator / denominator\nse <- sqrt(variance)\nse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4141.66\n```\n\n\n:::\n:::\n\n\n\n\n\nThat is the weighted sample mean and its accompanying weighted, sample standard error.\n\n\n\n::: {#tbl-wrong-se .cell tbl-cap='Standard Error via Sample Weights'}\n\n```{.r .cell-code}\nhouseholds_w_income %>%\n  as_survey(weights=HHWT) %>%\n  summarise(weighted_mean = survey_mean(HHINCOME))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| weighted_mean| weighted_mean_se|\n|-------------:|----------------:|\n|      141001.2|         4142.847|\n\n</div>\n:::\n:::\n\n\n\n\n\n\nIn theory, the standard error of an estimate measures the variation of a\nstatistic across multiple samples of a given population. Our sample\nstandard error above, calculated using just the one sample, is just an\nestimate of that theoretical standard error. We can get a better estimate of that theoretical standard error using replicate weights.\n\nReplicate weights allow a single sample to simulate multiple samples, thus generating more\ninformed standard error estimates that more closely mimic the\ntheoretical basis of standard errors.\nhttps://usa.ipums.org/usa/repwt.shtml#q70\n\nHere we can see what replicate weights (in this case, individual\nreplicate weights) look like in our data. Each of `REPWTP`, 1 through 80,\nis a set of alternative individual weights, slightly different from the\n\"production weight,\" `PERWT`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhouseholds_w_income %>%\n  mutate(` ` = \"...\") %>% \n  select(c(HHINCOME, HHWT, REPWT1, REPWT2, ` `, REPWT79, REPWT80)) %>% \n  head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| HHINCOME| HHWT| REPWT1| REPWT2|    | REPWT79| REPWT80|\n|--------:|----:|------:|------:|:---|-------:|-------:|\n|   129200|   50|     80|     47|... |      49|      50|\n|   107000|   73|     20|     25|... |      72|      74|\n|   138000|   74|     86|     85|... |      21|      73|\n|    44800|   41|     12|     43|... |      39|      44|\n|   380000|  311|     99|     86|... |     323|     105|\n|   189150|   65|     22|     20|... |     108|     122|\n\n</div>\n:::\n:::\n\n\n\n\nWe can use replicate weights in a variety of alternative variance\nestimates in the calculation of \"successive difference replication (SDR)\nvariance,\" an alternative to the standard variance of an estimate. We\nobtain SDR variance by calculating a statistic of interest with the\nproduction weights (e.g. `HHWT`), then sum the squared deviations\nbetween that production weighted estimate and the weighted estimates we\nobtain with each replicate weight (e.g. `REPWT1`). Specifically:\n$$\n\\begin{align*}\n\\bar{x}_w &= \\frac{\\sum_{i=1}^{n}w_ix_i}{\\sum_{i=1}^{n}w_i} \\\\ \n\\bar{x}_r &= \\frac{\\sum_{i=1}^{n}r_ix_i}{\\sum_{i=1}^{n}r_i} \\\\ \nSE(\\bar{x}_w) &= \\sqrt{\\frac{4}{80} \\sum_{r=1}^{80} (\\bar{x}_r - \\bar{x}_w)^2}\n\\end{align*}\n$$\n\nWhere $w$ represents the production weights, $r$ represents each\nreplicate weight. There are a few ways you can rationalize this equation to yourself.\n\n1. It's equivalent to using [Fay's Balanced Repeated Replication method](https://documentation.sas.com/doc/en/statug/15.2/statug_surveyphreg_details29.htm#:~:text=the%20following%20section.-,Fay%E2%80%99s%20BRR%20Method,-The%20traditional%20BRR) with the Faye coefficient set to $\\epsilon=.5$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate X_r\nX_r <- vector()\nfor (r in 1:80){\n  X_r[r] <- households_w_income %>%\n    as_survey(weights=glue(\"REPWT\", r)) %>%\n    summarise(weighted_mean = survey_mean(HHINCOME)) %>% \n    .$weighted_mean\n}\n# Calculate X\nX <- households_w_income %>%\n    as_survey(weights=HHWT) %>%\n    summarise(weighted_mean = survey_mean(HHINCOME)) %>% \n    .$weighted_mean\n\n\n# Sum over r\nsqrt( (4/80) * sum( (X_r - mean(X_r))^2 ) )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3435.34\n```\n\n\n:::\n:::\n\n\n\n\nTo be clear, we don't have to ever do that manually -- `survey` supports\nspecifying survey designs with replicate weights. Here we can\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhouseholds_w_income %>% \n  as_survey_rep(\n  weight = HHWT ,\n  repweights = matches(\"REPWT[0-9]+\"),\n  type = \"Fay\",\n  rho=.5,\n  mse = FALSE,\n) %>% summarise(mean_female_income = survey_mean(HHINCOME))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| mean_female_income| mean_female_income_se|\n|------------------:|---------------------:|\n|           141001.2|               3435.34|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhouseholds_w_income %>% \n  as_survey_rep(\n  weight = HHWT ,\n  repweights = matches(\"REPWT[0-9]+\"),\n  type = \"successive-difference\",\n  mse = FALSE,\n) %>% summarise(mean_female_income = survey_mean(HHINCOME))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| mean_female_income| mean_female_income_se|\n|------------------:|---------------------:|\n|           141001.2|               3435.34|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhouseholds_w_income %>% \nas_survey_rep(\n  weight = HHWT,\n  repweights = matches(\"REPWTP[0-9]+\"),\n  type = \"JK1\",\n  scale = 4 / 80 ,\n  rscales = rep(1, 80),\n  mse = TRUE) %>% summarise(mean_female_income = survey_mean(HHINCOME))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| mean_female_income| mean_female_income_se|\n|------------------:|---------------------:|\n|           141001.2|               3434.24|\n\n</div>\n:::\n:::\n\n\n\n\n\nIn IPUMS testing of ACS/PRCS data, replicate weights usually increase\nstandard errors. This increase is generally not large enough to alter\nthe significance level of coefficients, though marginally significant\ncoefficients may become clearly non-significant. The more obvious effect\nof using replicate weights is on the width of confidence intervals,\nwhich can change substantially.\n\nIPUMS' documentation recommends the following specification for the\nreplicate weights, where the standard errors are calculated via a\n[jacknife](https://en.wikipedia.org/wiki/Jackknife_resampling) (see\n`type = 'JK1'`).\n\n\n\n### Analyzing ACS microdata\n\nHere we can see the un-adjusted gender earnings gap in Oakland, where\nmen on earn about \\$20k more than women on average:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nindividuals_w_income <- oak %>%\n  # Find adult earners\n  filter(INCTOT != 9999999, INCTOT > 0, AGE >= 18) %>%\n  mutate(\n    # Label sex\n    SEX = case_when(SEX == 1 ~ 'Male', TRUE ~ 'Female'),\n    # Label education\n    educ_attain = case_when(\n      EDUC == 10 ~ \"Bachelor's degree\",\n      EDUC == 11 ~ \"Graduate degree\",\n      EDUCD %in% c(63, 65, 64) ~ \"Highschool diploma\",\n      EDUCD == 71 ~ \"Some college\",\n      EDUC == 8 ~ \"Associate's degree\",\n      EDUC == 0 ~ \"No schooling\",\n      EDUCD == 61 ~ \"Some school\",\n      EDUC < 6 ~ \"Some school\",\n    ) %>% as.factor()\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noak_indiv_svy <- as_survey_rep(\n  individuals_w_income,\n  weight = PERWT ,\n  repweights = matches(\"REPWTP[0-9]+\"),\n  type = \"JK1\",\n  scale = 4 / 80 ,\n  rscales = rep(1, 80),\n  mse = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noak_indiv_svy %>%\n  group_by(SEX) %>%\n  summarize(mean_income = survey_mean(INCTOT))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|SEX    | mean_income| mean_income_se|\n|:------|-----------:|--------------:|\n|Female |    71669.67|       2481.816|\n|Male   |    90114.19|       2742.858|\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\nLets explore a couple other dynamics related to earnings in Oakland and\npractice making visualizations and estimating regressions with the data.\nHere's the income distribution across different levels of highest\neducation earned. Note here that I'm not using the replicate weights\n(I'm just using the `individuals_w_income` object), since I'm not\nestimating anything. `ggplot` does take a weight argument, for which\nI've supplied the `PERWT` sample weights.\n\n<https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/index.html>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\norder <- individuals_w_income %>%\n  distinct(EDUC, educ_attain) %>%\n  arrange(EDUC) %>%\n  distinct(educ_attain) %>%\n  pull()\n\nggplot(individuals_w_income, aes(\n  x = factor(educ_attain, levels = order),\n  y = INCTOT,\n  weight = PERWT\n)) +\n  geom_jitter(\n    position = position_jitter(width = .2),\n    alpha = 0.6,\n    color = \"grey\",\n    size = 1.2\n  ) +\n  geom_boxplot(\n    alpha = 0.9,\n    color = \"black\",\n    size = .9,\n    outliers = FALSE,\n    linewidth = .8\n  ) +\n  scale_y_continuous(\n    labels = scales::label_currency(scale_cut = scales::cut_short_scale()),\n    limits = c(0, 500000),\n    breaks = seq(0, 500000, 100000)\n  ) +\n  scale_x_discrete(labels = scales::label_wrap(10)) +\n  labs(title = \"Income by Education Level\", y = \"Income\", x = \"Education Level\") +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid = element_line(\n      color = \"lightgrey\",\n      size = .2,\n      linetype = 1\n    ),\n    panel.background = element_rect(\"white\")\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\nThe plot shows that individuals with bachelor's and graduate degrees\ngenerally have higher incomes in Oakland. Let's seen how bachelor and\ngraduate degree attainment differs across sex. Again, I'm using the\n`individuals_w_income` object as I have no need to replicate weights.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncolors <- RColorBrewer::brewer.pal(n = 5, \"Set1\")[c(5, 2)]\n\norder <- individuals_w_income %>% distinct(EDUC, educ_attain) %>% arrange(desc(EDUC)) %>% distinct(educ_attain) %>% pull()\n\nggplot(individuals_w_income,\n       aes(\n         y = factor(educ_attain, level = order),\n         color = factor(SEX),\n         fill = factor(SEX),\n         weight = PERWT\n       )) +\n  geom_bar(\n    position = \"dodge\",\n    boundary = 0,\n    alpha = 0.9,\n    aes(x = (..count..) / sum(..count..))\n  ) +\n  scale_color_manual(values = colors) +\n  scale_fill_manual(values = colors) +\n  scale_x_continuous(labels = scales::label_percent(), ) +\n  labs(\n    title = \"Distribution of Highest Education Level by Sex\",\n    x = \"Percent of earners\",\n    y = \"Education\",\n    color = \"Sex\",\n    fill = \"Sex\"\n  ) +\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid = element_line(\n      color = \"lightgrey\",\n      size = .2,\n      linetype = 1\n    ),\n    panel.background = element_rect(\"white\")\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n\nSo bachelor and graduate degree holders generally earn more, and women\nare more likely than men to have bachelor and graduate degrees in\nOakland. This should imply that if we adjust for education when\nestimating the gender-earnings gap in Oakland, thus only comparing men\nand women in the same education levels, we should see the gap increase.\n\nWe again use `svyglm` to estimate the regression, and `oak_indiv_svy` as\nthe data/survey design so as to use the replicate weights for our\nstandard errors.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_ols2 <- svyglm(log(INCTOT) ~ factor(SEX), oak_indiv_svy)\nmodel_ols3 <- svyglm(\n  log(INCTOT) ~ factor(SEX) +\n    AGE + I(AGE ^ 2) +\n    relevel(educ_attain, ref =\"Highschool diploma\"),\n  oak_indiv_svy\n)\nmodelsummary(\n  list(\n    \"Earnings gap, no covariates\" = model_ols2,\n    \"Earnings gap, adjusted for age and education\" = model_ols3\n  ),\n  gof_map = gof_stuff,\n  exponentiate = TRUE\n)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<!-- preamble start -->\n\n    <script>\n\n      function styleCell_385vecy7vcg48ezgfka8(i, j, css_id) {\n          var table = document.getElementById(\"tinytable_385vecy7vcg48ezgfka8\");\n          var cell = table.rows[i]?.cells[j];  // Safe navigation to avoid errors\n          if (cell) {\n              console.log(`Styling cell at (${i}, ${j}) with class ${css_id}`);\n              cell.classList.add(css_id);\n          } else {\n              console.warn(`Cell at (${i}, ${j}) not found.`);\n          }\n      }\n      function insertSpanRow(i, colspan, content) {\n        var table = document.getElementById('tinytable_385vecy7vcg48ezgfka8');\n        var newRow = table.insertRow(i);\n        var newCell = newRow.insertCell(0);\n        newCell.setAttribute(\"colspan\", colspan);\n        // newCell.innerText = content;\n        // this may be unsafe, but innerText does not interpret <br>\n        newCell.innerHTML = content;\n      }\n      function spanCell_385vecy7vcg48ezgfka8(i, j, rowspan, colspan) {\n        var table = document.getElementById(\"tinytable_385vecy7vcg48ezgfka8\");\n        const targetRow = table.rows[i];\n        const targetCell = targetRow.cells[j];\n        for (let r = 0; r < rowspan; r++) {\n          // Only start deleting cells to the right for the first row (r == 0)\n          if (r === 0) {\n            // Delete cells to the right of the target cell in the first row\n            for (let c = colspan - 1; c > 0; c--) {\n              if (table.rows[i + r].cells[j + c]) {\n                table.rows[i + r].deleteCell(j + c);\n              }\n            }\n          }\n          // For rows below the first, delete starting from the target column\n          if (r > 0) {\n            for (let c = colspan - 1; c >= 0; c--) {\n              if (table.rows[i + r] && table.rows[i + r].cells[j]) {\n                table.rows[i + r].deleteCell(j);\n              }\n            }\n          }\n        }\n        // Set rowspan and colspan of the target cell\n        targetCell.rowSpan = rowspan;\n        targetCell.colSpan = colspan;\n      }\n      // tinytable span after\n      window.addEventListener('load', function () {\n          var cellsToStyle = [\n            // tinytable style arrays after\n          { positions: [ { i: 0, j: 1 }, { i: 0, j: 2 },  ], css_id: 'tinytable_css_n5oulf5ntayq56h7mz0z',}, \n          { positions: [ { i: 22, j: 0 },  ], css_id: 'tinytable_css_fdb2hvyh1dxktbqaylod',}, \n          { positions: [ { i: 0, j: 0 },  ], css_id: 'tinytable_css_edboomrj03lnsmr6ijkc',}, \n          { positions: [ { i: 20, j: 2 }, { i: 20, j: 1 },  ], css_id: 'tinytable_css_bp3kl56jkm9yddf2dmko',}, \n          { positions: [ { i: 1, j: 1 }, { i: 3, j: 1 }, { i: 4, j: 1 }, { i: 5, j: 1 }, { i: 2, j: 1 }, { i: 7, j: 1 }, { i: 8, j: 1 }, { i: 9, j: 1 }, { i: 6, j: 1 }, { i: 11, j: 1 }, { i: 12, j: 1 }, { i: 13, j: 1 }, { i: 14, j: 1 }, { i: 15, j: 1 }, { i: 16, j: 1 }, { i: 17, j: 1 }, { i: 18, j: 1 }, { i: 19, j: 1 }, { i: 10, j: 2 }, { i: 21, j: 1 }, { i: 12, j: 2 }, { i: 10, j: 1 }, { i: 1, j: 2 }, { i: 2, j: 2 }, { i: 3, j: 2 }, { i: 4, j: 2 }, { i: 5, j: 2 }, { i: 6, j: 2 }, { i: 7, j: 2 }, { i: 8, j: 2 }, { i: 9, j: 2 }, { i: 14, j: 2 }, { i: 11, j: 2 }, { i: 16, j: 2 }, { i: 13, j: 2 }, { i: 18, j: 2 }, { i: 15, j: 2 }, { i: 17, j: 2 }, { i: 19, j: 2 }, { i: 21, j: 2 },  ], css_id: 'tinytable_css_92dgcpa2j7cv97hbjts2',}, \n          { positions: [ { i: 1, j: 0 }, { i: 2, j: 0 }, { i: 3, j: 0 }, { i: 4, j: 0 }, { i: 5, j: 0 }, { i: 6, j: 0 }, { i: 7, j: 0 }, { i: 8, j: 0 }, { i: 9, j: 0 }, { i: 10, j: 0 }, { i: 11, j: 0 }, { i: 12, j: 0 }, { i: 13, j: 0 }, { i: 14, j: 0 }, { i: 15, j: 0 }, { i: 16, j: 0 }, { i: 17, j: 0 }, { i: 18, j: 0 }, { i: 19, j: 0 }, { i: 21, j: 0 },  ], css_id: 'tinytable_css_84pyqvwdoa4y201vgm47',}, \n          { positions: [ { i: 20, j: 0 },  ], css_id: 'tinytable_css_3tx7cgzsn7pwqsjhjbtl',}, \n          { positions: [ { i: 22, j: 1 }, { i: 22, j: 2 },  ], css_id: 'tinytable_css_0bipq2oc1isjvn6p8uit',}, \n          ];\n\n          // Loop over the arrays to style the cells\n          cellsToStyle.forEach(function (group) {\n              group.positions.forEach(function (cell) {\n                  styleCell_385vecy7vcg48ezgfka8(cell.i, cell.j, group.css_id);\n              });\n          });\n      });\n    </script>\n\n    <style>\n      /* tinytable css entries after */\n      .table td.tinytable_css_n5oulf5ntayq56h7mz0z, .table th.tinytable_css_n5oulf5ntayq56h7mz0z { text-align: center; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; }\n      .table td.tinytable_css_fdb2hvyh1dxktbqaylod, .table th.tinytable_css_fdb2hvyh1dxktbqaylod { text-align: left; border-bottom: solid #d3d8dc 0.1em; }\n      .table td.tinytable_css_edboomrj03lnsmr6ijkc, .table th.tinytable_css_edboomrj03lnsmr6ijkc { text-align: left; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; }\n      .table td.tinytable_css_bp3kl56jkm9yddf2dmko, .table th.tinytable_css_bp3kl56jkm9yddf2dmko { text-align: center; border-bottom: solid black 0.05em; }\n      .table td.tinytable_css_92dgcpa2j7cv97hbjts2, .table th.tinytable_css_92dgcpa2j7cv97hbjts2 { text-align: center; }\n      .table td.tinytable_css_84pyqvwdoa4y201vgm47, .table th.tinytable_css_84pyqvwdoa4y201vgm47 { text-align: left; }\n      .table td.tinytable_css_3tx7cgzsn7pwqsjhjbtl, .table th.tinytable_css_3tx7cgzsn7pwqsjhjbtl { text-align: left; border-bottom: solid black 0.05em; }\n      .table td.tinytable_css_0bipq2oc1isjvn6p8uit, .table th.tinytable_css_0bipq2oc1isjvn6p8uit { text-align: center; border-bottom: solid #d3d8dc 0.1em; }\n    </style>\n    <div class=\"container\">\n      <table class=\"table table-borderless\" id=\"tinytable_385vecy7vcg48ezgfka8\" style=\"width: auto; margin-left: auto; margin-right: auto;\" data-quarto-disable-processing='true'>\n        <thead>\n        \n              <tr>\n                <th scope=\"col\"> </th>\n                <th scope=\"col\">Earnings gap, no covariates</th>\n                <th scope=\"col\">Earnings gap, adjusted for age and education</th>\n              </tr>\n        </thead>\n        \n        <tbody>\n                <tr>\n                  <td>(Intercept)                                                       </td>\n                  <td>37064.571 </td>\n                  <td>3805.220 </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>(1610.829)</td>\n                  <td>(726.915)</td>\n                </tr>\n                <tr>\n                  <td>factor(SEX)Male                                                   </td>\n                  <td>1.251     </td>\n                  <td>1.378    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>(0.064)   </td>\n                  <td>(0.067)  </td>\n                </tr>\n                <tr>\n                  <td>AGE                                                               </td>\n                  <td>          </td>\n                  <td>1.074    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.009)  </td>\n                </tr>\n                <tr>\n                  <td>I(AGE^2)                                                          </td>\n                  <td>          </td>\n                  <td>0.999    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.000)  </td>\n                </tr>\n                <tr>\n                  <td>relevel(educ_attain, ref = \"Highschool diploma\")Associate's degree</td>\n                  <td>          </td>\n                  <td>1.466    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.176)  </td>\n                </tr>\n                <tr>\n                  <td>relevel(educ_attain, ref = \"Highschool diploma\")Bachelor's degree </td>\n                  <td>          </td>\n                  <td>2.880    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.198)  </td>\n                </tr>\n                <tr>\n                  <td>relevel(educ_attain, ref = \"Highschool diploma\")Graduate degree   </td>\n                  <td>          </td>\n                  <td>4.377    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.291)  </td>\n                </tr>\n                <tr>\n                  <td>relevel(educ_attain, ref = \"Highschool diploma\")No schooling      </td>\n                  <td>          </td>\n                  <td>0.743    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.087)  </td>\n                </tr>\n                <tr>\n                  <td>relevel(educ_attain, ref = \"Highschool diploma\")Some college      </td>\n                  <td>          </td>\n                  <td>1.171    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.132)  </td>\n                </tr>\n                <tr>\n                  <td>relevel(educ_attain, ref = \"Highschool diploma\")Some school       </td>\n                  <td>          </td>\n                  <td>0.774    </td>\n                </tr>\n                <tr>\n                  <td>                                                                  </td>\n                  <td>          </td>\n                  <td>(0.074)  </td>\n                </tr>\n                <tr>\n                  <td>N                                                                 </td>\n                  <td>3131      </td>\n                  <td>3131     </td>\n                </tr>\n                <tr>\n                  <td>R²                                                                </td>\n                  <td>0.007     </td>\n                  <td>0.308    </td>\n                </tr>\n        </tbody>\n      </table>\n    </div>\n<!-- hack to avoid NA insertion in last line -->\n```\n\n:::\n:::\n\n\n\n\nFun!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}