---
title: "Getting census data with the ipums API"
bibliography: "../../blog.bib"
author: "Peter Amerkhanian"
date: "2024-9-1"
draft: false
image: thumbnail.png
engine: knitr
categories: ['R', 'Data Management']
format:
  html:
    df-print: kable
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: true
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| output: false
library(ipumsr)
library(tidycensus)
library(ggplot2)
library(dplyr)
library(sf)
```

```{r}
#| output: false
# Note -- I store my ipums api key in the .Renviron file
set_ipums_api_key(Sys.getenv("ipums_api_key"))
# Note -- I store my census api key in the .Renviron file
census_api_key(Sys.getenv("census_api_key"))
```
```{r}
# Get median income data for Alameda County census tracts
alameda_income <- get_acs(
  geography = "tract",
  variables = "B19013_001", # Median household income
  state = "CA",
  county = "Alameda",
  geometry = TRUE, # Download geometries for spatial plotting
  year = 2022, # Year of the ACS
  survey = "acs5" # 1-year ACS data
)

# View the data
head(alameda_income)
```
```{r}
# Plot median income as a heatmap

x_limits <- c(-122.4, -122.0)  # Longitude limits
y_limits <- c(37.65, 37.91)

ggplot(alameda_income) +
  geom_sf(aes(fill = estimate), color = NA, alpha=.9) + # `estimate` contains median income
  scale_fill_viridis_c(option = "plasma", name = "Median Income") + # Color scale
  labs(
    title = "Median Household Income by Census Tract in Alameda County, CA",
    subtitle = "American Community Survey 5-Year Estimates",
    caption = "Source: U.S. Census Bureau"
  ) +
  coord_sf(xlim = x_limits, ylim = y_limits, expand = FALSE) + 
  theme_minimal() +
  theme(
    panel.background = element_rect(fill = "white"),
    panel.grid.major = element_line(color = "gray80")
  )

```
```{r}
# Retrieve poverty data for Oakland (place level)
oakland_stats <- get_acs(
  geography = "place",
  variables = c(
    median_hh_income = "B19013_001", # Median household income
    total_pop = "B17001_001",  # Total population for poverty status determination
    below_poverty = "B17001_002"  # Population below the poverty level
  ),
  state = "CA",
  year = 2022,  # Adjust the year for ACS 5-year estimates
  survey = "acs1"  # Use 5-year ACS estimates
)

oakland_stats <- oakland_stats %>% tibble() %>% filter(GEOID == '0653000')
oakland_stats
```


I often want to reference 
## What is IPUMS?

> IPUMS provides census and survey data from around the world integrated
> across time and space. IPUMS integration and documentation makes it
> easy to study change, conduct comparative research, merge information
> across data types, and analyze individuals within family and community
> contexts. Data and services available free of charge. -- \[\@\]

## How is IPUMS Different than census.gov

[@walker_analyzing_2023, chapter 9]

```{r}
ipums_data_collections() %>%
  filter(collection_type == "microdata",
         api_support == TRUE)
```

For analysis of populations in the U.S., the IPUMS USA and IPUMS CPS collections are of particular interest:

IPUMS USA: IPUMS USA collects, preserves and harmonizes U.S. census
microdata and provides easy access to this data with enhanced
documentation. Data includes decennial censuses from 1790 to 2010 and American Community Surveys (ACS) from 2000 to the present [@ruggles_ipums_2024].

We can check out the newest products they have in the USA collection as
follows:

```{r}
get_sample_info(collection="usa") %>% arrange(desc(name)) %>% head(10)
```


```{r}
get_sample_info(collection="usa") %>%
  filter(stringr::str_detect(description, "ACS")) %>%
  arrange(desc(name)) %>%
  head(10)
```

I'll define a function, `retrieve_alameda_sample()` that accomplishes that and only run the IPUMS request if I don't already have the data locally.

```{r}
#| code-fold: true
retrieve_alameda_sample <- function(){
  extract <- define_extract_usa(
    description = "Alameda County Incomes by PUMA",
    samples = c("us2022a"),
    variables = list(
      "COUNTYFIP",
      "PUMA",
      "FAMUNIT",
      "RELATE",
      "AGE",
      "SEX",
      "POVERTY",
      "FTOTINC",
      "HHINCOME",
      "INCTOT",
      var_spec("STATEFIP", case_selections = "06")
    )
  )
  data_path <- extract %>%
    submit_extract() %>%
    wait_for_extract() %>%
    download_extract(download_dir = here::here("data"),
                     overwrite = TRUE)
  data <- read_ipums_micro(data_path)
  return(data)
  }
```

```{r}
local_ipums_extracts <- list.files(
  path <- here::here('data'),
  pattern = "\\.xml$",
  full.names = TRUE)
```

```{r}
if (length(local_ipums_extracts) > 0) {
  existing_path <- local_ipums_extracts[1]
  data <- read_ipums_micro(existing_path)
} else {
  data <- retrieve_alameda_sample()
}
```

Use the [2020 PUMA
Names](https://www2.census.gov/geo/pdfs/reference/puma2020/2020_PUMA_Names.pdf).

```{r}
library(dplyr)
oak <- data %>%
  filter(PUMA %in% c(111, 112, 113, 123))

households <- oak %>%
  filter(! HHINCOME %in% c(9999999, 0, 9999998)) %>%
  # distinct(SERIAL, .keep_all = TRUE) %>%
  mutate(in_pov = (POVERTY <= 100) %>% as.factor)
```

```{r}
households %>% select(HHINCOME) %>% summary()
```


```{r}
library(ggstats)
weighted.median(households$HHINCOME, households$HHWT)
```


```{r}
oakland_stats
```




```{r}
# library(reticulate)
# use_condaenv("base")
```

```{python}
# import pandas as pd
# import matplotlib.pyplot as plt
# import numpy as np
# import skl
# 
# x = np.random.normal(0, 1, 10)
# y = np.random.normal(0, 1, 10)

```

```{python}
# fig, ax = plt.subplots()
# df['FTOTINC'].hist(ax=ax)
# plt.show()
```

```{r}
# plot(mtcars$mpg * 3)
```


```{r}
# <!-- null_dist <- families %>% -->
# <!--   specify(response = in_pov, success = "TRUE") %>%  -->
# <!--   hypothesize(null = "point", p=0) %>%  -->
# <!--   generate(reps = 1000, type = "bootstrap") %>%  -->
# <!--   calculate(stat = "prop") -->
# 
# <!-- point_estimate <- families %>% -->
# <!--   specify(response =in_pov, success = "TRUE") %>%  -->
# <!--   calculate(stat = "prop") -->
# 
# <!-- null_dist %>% visualise() -->
```

```{r}
# null_dist %>%
#   # calculate the confidence interval around the point estimate
#   get_confidence_interval(point_estimate = point_estimate,
#                           # at the 95% confidence level
#                           level = .95,
#                           # using the standard error
#                           type = "se")
```


