---
title: "Working with ACS microdata in R"
bibliography: "../../blog.bib"
author: "Peter Amerkhanian"
date: "2024-12-29"
description: "A general overview of retrieving and working with IPUMS data in R using `ipumsr` and `survey`."
draft: true
image: thumbnail.png
engine: knitr
execute: 
  cache: false
  freeze: auto
categories: ['R', 'Data Management']
format:
  html:
    df-print: kable
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: true
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| code-fold: true
#| output: false
pacman::p_load(dplyr,
               ggplot2,
               # Statistics
               modelsummary,
               srvyr,
               survey,
               # Webscraping
               httr,
               rvest,
               readr,
               glue,
               # Census
               tidycensus,
               ipumsr)

gof_stuff <- tribble(
  ~ raw, ~ clean, ~ fmt,
  "nobs", "N", 0,
  "r.squared", "R²", 3
  )
```

In this post, I'm going to cover how to use American Community Survey
(ACS) microdata, leveraging the University of Minnesota's Integrated
Public Use Microdata Series (IPUMS).[^1] I'll cover:

[^1]: I want to note that several of the points I cover here are things
    I learned from some coworkers-- [Bert
    Wilden](https://www.bwilden.com/) and Stephanie Peng.

1.  **Retrieval**: how to choose which ACS product is relevant, how to
    submit a request to IPUMS, and how to filter down to relevant levels
    of geography/granularity.
2.  **Analysis**: how to properly weight ACS data using sample and
    replication weights for accurate analysis and uncertainty estimation.

I'll start with a question: **What was the median household income in
Oakland, California in 2022?**

## Aggregate data with `tidycensus`

Answering that question is straightforward using *aggregate* data from
the U.S. Census, which provides various descriptive statistics for
aggregate geographies. I might use a web-based tool like [Census
Reporter](https://censusreporter.org/) to quickly look it up, but for an
analysis, I would like the data retrieval to be carried out
transparently via an API.

In R, the `tidycensus` package provides an easy-to-use wrapper for the
Census API. Note that I set up an API key for the U.S. Census and I'm
storing it in my `.Renviron` file as `census_api_key`.
```{r}
#| output: false
#| warning: false
census_api_key(Sys.getenv("census_api_key"))
```

I query `B19013_001`, the median household income variable, using the
2022 1-year American Community Survey sample and I filter down to
Oakland's GEOID, `0653000`, which is a combination of the state code for
California, `06`, and the place code for Oakland, `53000`.[^2] I'll throw in
the total population variable for good measure:

[^2]: See the [full variable list for the 2022 1-year
    ACS](https://api.census.gov/data/2022/acs/acs1/variables.html) for
    the available variables, and see the [Census Place
    table](https://www.census.gov/library/reference/code-lists/ansi.html#place)
    for looking up GEOIDs

```{r}
#| warning: false
oakland_stats <- get_acs(
  geography = "place",
  variables = c(
    median_hh_income = "B19013_001",
    total_pop = "B17001_001"
  ),
  state = "CA",
  year = 2022,
  survey = "acs1"
)
oakland_stats <- oakland_stats %>% filter(GEOID == '0653000')
oakland_stats %>% select(c(variable, estimate, moe))
```

Done! We now know the population and median household income for Oakland in 2022, along with a margin of error. See [@walker_analyzing_2023] for a comprehensive treatment of working with aggregate census data.

## Microdata with IPUMS

What if I wanted to have access to the underlying data used to calculate the median? Maybe I want to try a different standard error specification for that statistic, or calculate other statistics, like the average household income. These tasks would all entail accessing census *microdata* -- household level and/or individual level census data.

One of the most popular sources for downloading census microdata is the
University of Minnesota's Integrated Public Use Microdata Series
(IPUMS). The IPUMS team provides a centralized API for downloading
census microdata, comprehensive documentation for working with the data, and harmonized variables across time [@walker_analyzing_2023,
chapter 9].

The easiest way to access IPUMS data in R is with the [`ipumsr`](https://tech.popdata.org/ipumsr/) package,
which the IPUMS team maintains [@greg_freedman_ellis_ipumsr_2024] and which allows users to submit API requests to IPUMS directly from R. To get set up, I [registered for an IPUMS API key](https://developer.ipums.org/docs/v2/get-started/), stored the key in my `.Renviron` file, and will configure the key in `ipumsr` as follows:

```{r}
#| output: false
set_ipums_api_key(Sys.getenv("ipums_api_key"))
```

The `ipumsr` website [provides
details](https://tech.popdata.org/ipumsr/articles/ipums.html#obtaining-data-via-the-ipums-api) on what survey products the project currently supports, as does
the `ipums_data_collections()` function:

```{r}
ipums_data_collections() %>%
  filter(api_support == TRUE) %>% 
  arrange(desc(collection_type))
```

I'll look at IPUMS USA since my motivating question
involves median household income for a year (2022), and IPUMS USA offers
annual data from decennial censuses 1790-2010 and American Community
Surveys (ACS) 2000-present [@ruggles_ipums_2024]. We can check out the
newest products they have in the USA collection as follows:

```{r}
get_sample_info(collection="usa") %>%
  arrange(desc(name)) %>%
  head(5)
```

Note that "PRCS" refers to the Puerto Rico Community Survey (an ACS
equivalent specifically tailored to Puerto Rico). We are principally
interested in the ACS, which comes in either one-year (e.g. 2023 ACS) or five-year (e.g. 2018-2022, ACS 5-year) estimates. The differences between these two estimates are described in detail in
the [Census Data: An
Overview](https://walker-data.com/census-r/the-united-states-census-and-the-r-programming-language.html#census-data-an-overview)
in [@walker_analyzing_2023]. One differentiating point is that one-year estimates come from a smaller, but more contemporary sample. In our case we'll use the
one-year to get the best sense of the 2022 income dynamics.

### Step 1: Retrieving data

Let's return to the motivating question for this post: **What was the
median household income in Oakland, California in 2022?**

To answer that we will:  

1. Get income data from the 2022 1-year ACS, 
2. Filter our data down to households in the city of Oakland, and
3. Calculate the median.

For the first task, I'll define a general function, `retrieve_sample()` that retrieves a list of variables from a given ACS sample.

```{r}
retrieve_sample <- function(sample, variables){
  extract <- define_extract_micro(description = "Incomes by PUMA",
                                  collection = "usa",
                                  samples = c(sample),
                                  variables = variables)
  data_path <- extract %>%
    submit_extract() %>%
    wait_for_extract() %>%
    download_extract(download_dir = here::here("data"),
                     overwrite = TRUE)
  data <- read_ipums_micro(data_path)
  return(data)
  }
```

I'll also define a list of variables that I want, including `HHINCOME`
(household income) and `INCTOT` (individual income). Some of these
variables refer to census-specific language – i.e. `PUMA` , `REPWT` ,
`REPWTP`. I'll cover exactly what each of these represent later in the
post.

```{r}
variables <- list(
  "PUMA",
  "AGE",
  "SEX",
  "EDUC",
  "HHINCOME",
  "INCTOT",
  "REPWT",
  "REPWTP",
  var_spec("STATEFIP",
           case_selections = "06")
)
```

Note the variable, `var_spec("STATEFIP", case_selections = "06")`. This
selects the variable `STATEFIP`, while also specifying that we want to
restrict our request to data where `STATEFIP=='06'` (California). Using
[`var_spec()`](https://tech.popdata.org/ipumsr/reference/var_spec.html)
is important, as accidentally/unnecessarily downloading an unfiltered, full sample of the entire U.S. is time-consuming.

Anyways, I can request these variables from the 2022 1-year ACS via the
function call, `retrieve_sample("us2022a", variables)`. However, I'll
first write code that checks if I've already downloaded the data before
running the query to avoid repeatedly downloading it.

```{r}
#| output: false
local_ipums_extracts <- list.files(
  path = here::here('data'),
  pattern = "\\.xml$",
  full.names = TRUE)
if (length(local_ipums_extracts) > 0) {
  existing_path <- local_ipums_extracts[1]
  data <- read_ipums_micro(existing_path)
} else {
  data <- retrieve_sample("us2022a", variables)
}
```

Here's the resulting data, the 2022 1-year ACS for California.

```{r}
#| label: tbl-raw
#| tbl-cap: "Unfiltered 2022 1-year ACS data for California"
data %>% head()
```

### Step 2: Using Geocorr to Identify Geographies

We now have microdata for all of California, but we need to filter down
to just Oakland. Unfortunately, this isn't as simple as just running
`filter(CITY == 'Oakland')` -- ACS microdata does not include a field
for explicitly identifying cities (note that a city is typically
referred to as a "place" in census data).

The smallest geographic area explicitly identified in the microdata is
something called a public use microdata area (PUMA) [@pastoor_how_2024].
PUMAS are unique geographies that always aggregate to the state-level
(e.g. California can be constructed with a collection of PUMAs), but
only sometimes aggregate to other small geographic areas, such as city,
metro area, and county [See [Census
Hierarchies](https://walker-data.com/census-r/the-united-states-census-and-the-r-programming-language.html#census-hierarchies)
in @walker_analyzing_2023, chapter 1].

To find out if a city corresponds to a collection of PUMAs and which
PUMAs those are, we'll use
[Geocorr](https://mcdc.missouri.edu/applications/geocorr2022.html)
(geographic correspondence engine), an application that generates
correlation lists showing relationships between two or more geographic
coverages in the United States [@mihalik_missouri_2022]. Geocorr is a
sponsored program of the Missouri State library and published by the
University of Missouri Center for Health Policy.[^3]

[^3]: I'll to note that the combination of IPUMS and Geocorr
    is a fantastic public good, and it's extremely generous of the
    public Universities of Minnesota and Missouri to publish these.

![Geocorr 2022: Geographic Correspondence
Engine](geocorr.png){width="80%"}

To use Geocorr, I'll define a function, `geocorr_2022()` that queries
Geocorr 2022 and retrieves a .csv file establishing the relationships
between two sets of geographies within a given state.

```{r}
geocorr_2022 <- function(state, geo_1, geo_2, weight_var) {
  base_url <- "https://mcdc.missouri.edu"
  params <- glue(
    "cgi-bin/broker?_PROGRAM=apps.geocorr2022.sas&",
    "_SERVICE=MCDC_long&_debug=0&",
    "state={state}&g1_={geo_1}&g2_={geo_2}&wtvar={weight_var}&",
    "nozerob=1&fileout=1&filefmt=csv&lstfmt=txt&title=&",
    "counties=&metros=&places=&oropt=&latitude=&longitude=&",
    "distance=&kiloms=0&locname=")
  initial_url <- params %>% url_absolute(base = base_url)
  initial_response <- GET(initial_url)
  html_content <- content(initial_response, as = "text")
  parsed_html <- read_html(html_content)
  # Extract the one link
  csv_url <- parsed_html %>%
    html_node("a") %>%
    html_attr("href") %>%
    stringr::str_trim() %>%
    url_absolute(base = base_url)
  csv_data <- read_csv(csv_url)
  return(csv_data)
}
```

We'll use that function to establish the relationships between
California's 2022 PUMAs and its "places," using individual population as
measured in the 2020 Decenial Census to weight the relationships.

```{r}
#| output: false
csv_data <- geocorr_2022("Ca06", "puma22", "place", "pop20")
```

With that, we can see which PUMAs correspond to the City of Oakland.

```{r}
#| label: tbl-correspondence
#| tbl-cap: "PUMA to Place correspondence for Oakand, CA"
csv_data %>%
  select(-c(state, stab, place, PUMA22name)) %>%
  filter(PlaceName == 'Oakland city, CA')
```

The `AFACT` (allocation factor) column shows the proportion of the
source area contained in the target area -- in this case the proportion
of the PUMA population that belongs to Oakland. In this case, 100% of
the populations in PUMAs 111, 112, 113, and 123 belong to Oakland, and
0% of PUMA 114. GEOCORR does believe that 9 individuals from 114 live in
Oakland, but based on the AFACT of 0, I'll feel comfortable dropping
that PUMA.[^4]

[^4]: Were the AFACT higher, e.g. 1%, I would randomly sample 1% of the
    individuals from that PUMA and include them in my Oakland sample.

Filtering to those PUMAs gets us the 2022 1-year ACS microdata for the
City of Oakland (note the use of `haven::zap_labels()` is just to remove
some unnecessary formatting that comes with the data).

```{r}
#| label: tbl-oakland-raw
#| tbl-cap: "2022 1-year ACS data for Oakland, CA"
oakland_pumas <- c(111, 112, 113, 123)
oak <- data %>%
  filter(PUMA %in% oakland_pumas) %>% 
  haven::zap_labels()
oak %>% head()
```

### Step 3: Filtering to desired granularity

Each row in the ACS microdata is an individual, identified by a unique
combination of `SAMPLE`, which defines the year when the individual was
surveyed, `SERIAL`, a unique identifier for that individual's household,
and `PERNUM`, a unique identifier for the individual within their
household [@ruggles_ipums_2024]. Thus, we can identify units as follows:

-   **Households**: The combination of `SAMPLE` and `SERIAL` provides a
    unique identifier for every household in the IPUMS
-   **Individuals**: The combination of `SAMPLE`, `SERIAL`, and `PERNUM`
    provides a unique identifier for every person in the IPUMS

We can group by these variable combinations and see how many individuals
and households were surveyed across PUMAs in Oakland for the 2022 1-year
ACS. We can see that each row in the data represents an individual
(`n_rows` equals `n_individuals`) and, as we would expect, the number of
households is much lower than the number of individuals.

```{r}
#| label: tbl-granularity
#| tbl-cap: "Oakland Dataset Granularity by PUMA"
oak %>% group_by(PUMA) %>% summarise(
  n_rows = n(),
  n_individuals = n_distinct(SAMPLE, SERIAL, PERNUM),
  n_households = n_distinct(SAMPLE, SERIAL)
  )
```

I'll also randomly select a household in the data to see what such a
unit looks like in practice.

```{r}
#| label: tbl-example-hh
#| tbl-cap: "An example household with income data"
#| code-fold: true

household_serials <- oak %>%
  group_by(SERIAL) %>%
  count() %>%
  filter(n > 1) %>%
  pull(SERIAL)
set.seed(2)
sample_household <- sample(household_serials, 1)
n <- oak %>% filter(SERIAL == sample_household) %>% dim() %>% .[1]
oak %>% filter(SERIAL == sample_household) %>% 
  select(c(SERIAL, PERNUM, AGE, SEX, HHINCOME, INCTOT))
```

Here we can see that this household, with `SERIAL`
`{r} format(sample_household, scientific=FALSE)` has `{r} n` members,
each with a unique `PERNUM`.

Let's return to the motivating question – **what was the median
household income in Oakland, California in 2022?** Note the income
variables we observe for this family:

1.  `INCTOT` reports each respondent's total pre-tax personal income or
    losses from all sources for the previous year. `9999999` is code to
    denote that the value is missing, which makes sense given that the
    missing values above correspond to children in the household [See
    [INCTOT](https://usa.ipums.org/usa-action/variables/INCTOT) in
    @ruggles_ipums_2024].

2.  `HHINCOME` reports the total money income of all household members
    age 15+ during the previous year. The amount should equal the sum of
    all household members' individual incomes, as recorded in the
    person-record variable INCTOT [See
    [HHINCOME](https://usa.ipums.org/usa-action/variables/HHINCOME) in
    @ruggles_ipums_2024]

Given what we know about the unique identifier for households, and the
`HHINCOME` variable, we can construct the appropriate dataset for
answering our motivating question – every household in Oakland that had
household income.

```{r}
households_w_income <- oak %>%
  distinct(SAMPLE, SERIAL, .keep_all = TRUE) %>% 
  filter(HHINCOME != 9999999, HHINCOME >= 0)
```

It seems we can proceed to simply calculate the median of the `HHINCOME`
column? Not so fast... Data in the ACS microdata are not what they seem.
Before we do any analysis, we have to account for **sample weights**.

### Step 4: Applying sample weights

Let's return to our sample family from above, but also examine the
variables `PERWT` and `HHWT`.

```{r}
#| label: tbl-example-hh-weights
#| tbl-cap: "An example household with weight data"
oak %>% filter(SERIAL == sample_household) %>% 
  select(c(AGE, SEX, HHINCOME, INCTOT, PERWT, HHWT))
```

These are the two primary sample weights in ACS microdata, and they can
be interpreted fairly directly. `PERWT` gives the population represented
by each individual in the sample, thus in the first row of the sample
household, the 31 year old woman with an individual income of \$9,300
represents 62 individuals in the PUMA. `HHWT` gives the number of
households in the general population represented by each household in
the sample, thus this household is representative of 62 households in
that PUMA.

Any person-level analysis of ACS microdata should be weighted by
`PERWT`, and household-level analysis should be weighted by `HHWT` [See
[Sample Weights](https://usa.ipums.org/usa/intro.shtml#weights) in
@ruggles_ipums_2024]. We'll use the
[`srvyr`](http://gdfe.co/srvyr/reference/index.html) package for easily
defining the survey weights and using them to calculate summary
statistics.

Here we'll finally address the motivating question. **The median
household income in Oakland in 2022** as measured in the IPUMS microdata
was as follows:

```{r}
#| label: tbl-answer
#| tbl-cap: "2022 Median Household Income in Oakland, CA"
households_w_income %>%
  as_survey(weights=HHWT) %>%
  summarise(weighted_median = survey_median(HHINCOME)) %>% 
  select(weighted_median)
```

Let's do a quick comparison of our IPUMS results to the aggregate census
data we retrieved in the first section. Here are our full IPUMS results
for both median household income and population:

```{r}
#| code-fold: true
#| label: tbl-ipums-res
#| tbl-cap: "IPUMS versus ACS aggregate results"
median_table <- households_w_income %>%
  as_survey(weights=HHWT) %>% 
  summarise(weighted_median = survey_median(HHINCOME)) %>% 
  mutate(variable = "median_hh_income",
         ipums_estimate = weighted_median,
         se = weighted_median_se)

count_table <- oak %>%
  as_survey(weights=PERWT) %>% 
  survey_count() %>% 
  mutate(variable = "total_pop",
         ipums_estimate = n,
         se = n_se)

aggregate_data <- oakland_stats %>%
  select(c(variable, estimate)) %>%
  rename(ACS_aggregate_estimate = estimate)

bind_rows(count_table, median_table) %>% 
  select(c(variable, ipums_estimate)) %>% inner_join(aggregate_data, by='variable')

```

These are clearly different. What gives? Unfortunately, **summary
statistics calculated using IPUMS data typically cannot match aggregate
ACS figures!**

One major reason for this gap is additional sampling error. Recall that
the American Community Survey is a sample. A given one-year ACS is
typically a 1% sample of the U.S. population, with associated sampling
error. When the census makes microdata available, they create a sample
of that sample -- we do not get the full 1%. This second sampling
process introduces further sampling error in the microdata that is not
reflected in figures sourced from aggregate ACS data, which are
calculated using the full ACS sample [[See
ACS](https://usa.ipums.org/usa/chapter2/chapter2.shtml#ACS) in
@ruggles_ipums_2024]. This introduces its own, additional sampling
error.[^5]

[^5]: Beyond that sampling error, the census applies various other
    additional data processing steps to microdata that aren't applied to
    aggregate figures [[See
    ACS](https://usa.ipums.org/usa/chapter2/chapter2.shtml#ACS) in
    @ruggles_ipums_2024]

### Step 5: Calculating Standard Errors

Now we have estimates derived from the ACS microdata, but recall that this is survey data. We are working with a small sample of Oakland's population, so we would assume that our estimates are likely going to be wrong by some degree, so accurately communicating uncertainty via good standard errors will be important.  

For the sake of this example, let's explore the problem of standard errors via a slightly different motivating question -- **what was the average household income in Oakland in 2022**? I'm switching to the average because we are about to calculate some standard errors from-scratch, and that's much more clear-cut for linear statistics like the average than for non-linear statistics like the median. We will return to the median at the end of this section, but rely on a package implementation and not do anything from-scratch.

Anyways, let's calculate the average household income in Oakland using the sample household weights. The [formula for the weighted average](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Mathematical_definition) is: 
$$
\bar{X}_w = \frac{\sum_{i=1}^{n}w_ix_i}{\sum_{i=1}^{n}w_i}
$$
We'll put that into code and get the following estimate of the average household income in Oakland:
```{r}
weighted_mean <- (
  sum(households_w_income$HHINCOME * households_w_income$HHWT)
  / sum(households_w_income$HHWT)
  )
weighted_mean
```
Now, let's get a standard error for that estimate. Correctly utilizing the sample weights in the variance calculation is [a little tricky](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Variance) and there are a few different approaches. Most packages (e.g. [SAS](https://documentation.sas.com/doc/en/statug/latest/statug_surveymeans_details06.htm#statug.surveymeans.variancedetails), [Stata](https://www.stata.com/manuals/svyvarianceestimation.pdf), and R's [`survey` package](https://r-survey.r-forge.r-project.org/survey/#:~:text=Variances%20by%20Taylor%20linearization)) default to using "linearized variance." In short, this entails calculating the first-order Taylor series approximation of the weighted mean formula above, then finding the variance of that approximation. Wikipedia has a nice [walkthrough of that calculation](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Variance_of_the_weighted_mean_(%CF%80-estimator_for_ratio-mean)), but the details are beyond the scope of this post -- we will just work with the resulting formula, the variance and standard error of the first-order linear approximation of the weighted mean:

$$
\begin{align*}
\hat{\text{Var}}(\bar{X}_w) &= \frac{\sum w_i^2 (x_i - \bar{X}_w)^2}{\left(\sum w_i\right)^2} \\
\hat{\text{SE}}(\bar{X}_w) &= \sqrt{\hat{\text{Var}}(\bar{X}_w)}
\end{align*}

$$

```{r}
numerator <- sum(households_w_income$HHWT^2 * (households_w_income$HHINCOME - weighted_mean)^2)
denominator <- sum(households_w_income$HHWT)^2
variance <- numerator / denominator
se <- sqrt(variance)
se
```


That is the weighted sample mean and its accompanying weighted, sample standard error.
```{r}
#| label: tbl-wrong-se
#| tbl-cap: "Standard Error via Sample Weights"
households_w_income %>%
  as_survey(weights=HHWT) %>%
  summarise(weighted_mean = survey_mean(HHINCOME))

```



In theory, the standard error of an estimate measures the variation of a
statistic across multiple samples of a given population. Our sample
standard error above, calculated using just the one sample, is just an
estimate of that theoretical standard error. We can get a better estimate of that theoretical standard error using replicate weights.

Replicate weights allow a single sample to simulate multiple samples, thus generating more
informed standard error estimates that more closely mimic the
theoretical basis of standard errors.
https://usa.ipums.org/usa/repwt.shtml#q70

Here we can see what replicate weights (in this case, individual
replicate weights) look like in our data. Each of `REPWTP`, 1 through 80,
is a set of alternative individual weights, slightly different from the
"production weight," `PERWT`.

```{r}
households_w_income %>%
  mutate(` ` = "...") %>% 
  select(c(HHINCOME, HHWT, REPWT1, REPWT2, ` `, REPWT79, REPWT80)) %>% 
  head()
```

We can use replicate weights in a variety of alternative variance
estimates in the calculation of "successive difference replication (SDR)
variance," an alternative to the standard variance of an estimate. We
obtain SDR variance by calculating a statistic of interest with the
production weights (e.g. `HHWT`), then sum the squared deviations
between that production weighted estimate and the weighted estimates we
obtain with each replicate weight (e.g. `REPWT1`). Specifically:
$$
\begin{align*}
\bar{x}_w &= \frac{\sum_{i=1}^{n}w_ix_i}{\sum_{i=1}^{n}w_i} \\ 
\bar{x}_r &= \frac{\sum_{i=1}^{n}r_ix_i}{\sum_{i=1}^{n}r_i} \\ 
SE(\bar{x}_w) &= \sqrt{\frac{4}{80} \sum_{r=1}^{80} (\bar{x}_r - \bar{x}_w)^2}
\end{align*}
$$

Where $w$ represents the production weights, $r$ represents each
replicate weight. There are a few ways you can rationalize this equation to yourself.

1. It's equivalent to using [Fay's Balanced Repeated Replication method](https://documentation.sas.com/doc/en/statug/15.2/statug_surveyphreg_details29.htm#:~:text=the%20following%20section.-,Fay%E2%80%99s%20BRR%20Method,-The%20traditional%20BRR) with the Faye coefficient set to $\epsilon=.5$.

```{r}
# Calculate X_r
X_r <- vector()
for (r in 1:80){
  X_r[r] <- households_w_income %>%
    as_survey(weights=glue("REPWT", r)) %>%
    summarise(weighted_mean = survey_mean(HHINCOME)) %>% 
    .$weighted_mean
}
# Calculate X
X <- households_w_income %>%
    as_survey(weights=HHWT) %>%
    summarise(weighted_mean = survey_mean(HHINCOME)) %>% 
    .$weighted_mean


# Sum over r
sqrt( (4/80) * sum( (X_r - mean(X_r))^2 ) )
```

To be clear, we don't have to ever do that manually -- `survey` supports
specifying survey designs with replicate weights. Here we can

```{r}
households_w_income %>% 
  as_survey_rep(
  weight = HHWT ,
  repweights = matches("REPWT[0-9]+"),
  type = "Fay",
  rho=.5,
  mse = FALSE,
) %>% summarise(mean_female_income = survey_mean(HHINCOME))
```


```{r}
households_w_income %>% 
  as_survey_rep(
  weight = HHWT ,
  repweights = matches("REPWT[0-9]+"),
  type = "successive-difference",
  mse = FALSE,
) %>% summarise(mean_female_income = survey_mean(HHINCOME))
```
```{r}
households_w_income %>% 
as_survey_rep(
  weight = HHWT,
  repweights = matches("REPWTP[0-9]+"),
  type = "JK1",
  scale = 4 / 80 ,
  rscales = rep(1, 80),
  mse = TRUE) %>% summarise(mean_female_income = survey_mean(HHINCOME))
```


In IPUMS testing of ACS/PRCS data, replicate weights usually increase
standard errors. This increase is generally not large enough to alter
the significance level of coefficients, though marginally significant
coefficients may become clearly non-significant. The more obvious effect
of using replicate weights is on the width of confidence intervals,
which can change substantially.

IPUMS' documentation recommends the following specification for the
replicate weights, where the standard errors are calculated via a
[jacknife](https://en.wikipedia.org/wiki/Jackknife_resampling) (see
`type = 'JK1'`).



### Analyzing ACS microdata

Here we can see the un-adjusted gender earnings gap in Oakland, where
men on earn about \$20k more than women on average:
```{r}
#| code-fold: true
individuals_w_income <- oak %>%
  # Find adult earners
  filter(INCTOT != 9999999, INCTOT > 0, AGE >= 18) %>%
  mutate(
    # Label sex
    SEX = case_when(SEX == 1 ~ 'Male', TRUE ~ 'Female'),
    # Label education
    educ_attain = case_when(
      EDUC == 10 ~ "Bachelor's degree",
      EDUC == 11 ~ "Graduate degree",
      EDUCD %in% c(63, 65, 64) ~ "Highschool diploma",
      EDUCD == 71 ~ "Some college",
      EDUC == 8 ~ "Associate's degree",
      EDUC == 0 ~ "No schooling",
      EDUCD == 61 ~ "Some school",
      EDUC < 6 ~ "Some school",
    ) %>% as.factor()
  )
```

```{r}
oak_indiv_svy <- as_survey_rep(
  individuals_w_income,
  weight = PERWT ,
  repweights = matches("REPWTP[0-9]+"),
  type = "JK1",
  scale = 4 / 80 ,
  rscales = rep(1, 80),
  mse = TRUE)
```

```{r}
oak_indiv_svy %>%
  group_by(SEX) %>%
  summarize(mean_income = survey_mean(INCTOT))
```


```{r}
#| warning: false
#| output: false
#| echo: false
library(reticulate)
use_condaenv('base')
```

```{python}
#| output: false
#| echo: false
#| 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.DataFrame(r['individuals_w_income'])

fig, ax = plt.subplots(figsize=(3, 3))
sns.kdeplot(data=df, x='INCTOT', y="AGE", weights="PERWT", ax=ax, fill=True, alpha=.5, log_scale=True, legend=False, cmap="coolwarm")
ax.set_axis_off()
ax.set_xlim(10e2, 10e5)
fig.tight_layout()
fig.savefig("thumbnail.png", dpi=300)
plt.show();
```


Lets explore a couple other dynamics related to earnings in Oakland and
practice making visualizations and estimating regressions with the data.
Here's the income distribution across different levels of highest
education earned. Note here that I'm not using the replicate weights
(I'm just using the `individuals_w_income` object), since I'm not
estimating anything. `ggplot` does take a weight argument, for which
I've supplied the `PERWT` sample weights.

<https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/index.html>

```{r}
#| warning: false
#| code-fold: true

order <- individuals_w_income %>%
  distinct(EDUC, educ_attain) %>%
  arrange(EDUC) %>%
  distinct(educ_attain) %>%
  pull()

ggplot(individuals_w_income, aes(
  x = factor(educ_attain, levels = order),
  y = INCTOT,
  weight = PERWT
)) +
  geom_jitter(
    position = position_jitter(width = .2),
    alpha = 0.6,
    color = "grey",
    size = 1.2
  ) +
  geom_boxplot(
    alpha = 0.9,
    color = "black",
    size = .9,
    outliers = FALSE,
    linewidth = .8
  ) +
  scale_y_continuous(
    labels = scales::label_currency(scale_cut = scales::cut_short_scale()),
    limits = c(0, 500000),
    breaks = seq(0, 500000, 100000)
  ) +
  scale_x_discrete(labels = scales::label_wrap(10)) +
  labs(title = "Income by Education Level", y = "Income", x = "Education Level") +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid = element_line(
      color = "lightgrey",
      size = .2,
      linetype = 1
    ),
    panel.background = element_rect("white")
  )
```



The plot shows that individuals with bachelor's and graduate degrees
generally have higher incomes in Oakland. Let's seen how bachelor and
graduate degree attainment differs across sex. Again, I'm using the
`individuals_w_income` object as I have no need to replicate weights.

```{r}
#| warning: false
#| code-fold: true

colors <- RColorBrewer::brewer.pal(n = 5, "Set1")[c(5, 2)]

order <- individuals_w_income %>% distinct(EDUC, educ_attain) %>% arrange(desc(EDUC)) %>% distinct(educ_attain) %>% pull()

ggplot(individuals_w_income,
       aes(
         y = factor(educ_attain, level = order),
         color = factor(SEX),
         fill = factor(SEX),
         weight = PERWT
       )) +
  geom_bar(
    position = "dodge",
    boundary = 0,
    alpha = 0.9,
    aes(x = (..count..) / sum(..count..))
  ) +
  scale_color_manual(values = colors) +
  scale_fill_manual(values = colors) +
  scale_x_continuous(labels = scales::label_percent(), ) +
  labs(
    title = "Distribution of Highest Education Level by Sex",
    x = "Percent of earners",
    y = "Education",
    color = "Sex",
    fill = "Sex"
  ) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid = element_line(
      color = "lightgrey",
      size = .2,
      linetype = 1
    ),
    panel.background = element_rect("white")
  )
```


So bachelor and graduate degree holders generally earn more, and women
are more likely than men to have bachelor and graduate degrees in
Oakland. This should imply that if we adjust for education when
estimating the gender-earnings gap in Oakland, thus only comparing men
and women in the same education levels, we should see the gap increase.

We again use `svyglm` to estimate the regression, and `oak_indiv_svy` as
the data/survey design so as to use the replicate weights for our
standard errors.

```{r}
model_ols2 <- svyglm(log(INCTOT) ~ factor(SEX), oak_indiv_svy)
model_ols3 <- svyglm(
  log(INCTOT) ~ factor(SEX) +
    AGE + I(AGE ^ 2) +
    relevel(educ_attain, ref ="Highschool diploma"),
  oak_indiv_svy
)
modelsummary(
  list(
    "Earnings gap, no covariates" = model_ols2,
    "Earnings gap, adjusted for age and education" = model_ols3
  ),
  gof_map = gof_stuff,
  exponentiate = TRUE
)
```

Fun!
